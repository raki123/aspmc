#!/usr/bin/env python
# -*- coding: utf-8 -*-

# CAVEAT UTILITOR
#
# This file was automatically generated by TatSu.
#
#    https://pypi.python.org/pypi/tatsu/
#
# Any changes you make to it will be overwritten the next time
# the file is generated.


from __future__ import generator_stop

import sys

from tatsu.buffering import Buffer
from tatsu.parsing import Parser
from tatsu.parsing import tatsumasu, leftrec, nomemo
from tatsu.parsing import leftrec, nomemo  # noqa
from tatsu.util import re, generic_main  # noqa

from semantics import ProblogSemantics

KEYWORDS = {}  # type: ignore


class ProblogBuffer(Buffer):
    def __init__(
        self,
        text,
        whitespace=None,
        nameguard=None,
        comments_re=None,
        eol_comments_re=None,
        ignorecase=None,
        namechars='',
        **kwargs
    ):
        super().__init__(
            text,
            whitespace=whitespace,
            nameguard=nameguard,
            comments_re=comments_re,
            eol_comments_re=eol_comments_re,
            ignorecase=ignorecase,
            namechars=namechars,
            **kwargs
        )

class ProblogParser(Parser):
    def __init__(
        self,
        whitespace=None,
        nameguard=None,
        comments_re=None,
        eol_comments_re=None,
        ignorecase=None,
        left_recursion=True,
        parseinfo=True,
        keywords=None,
        namechars='',
        tokenizercls=ProblogBuffer,
        **kwargs
    ):
        if keywords is None:
            keywords = KEYWORDS
        super().__init__(
            whitespace=whitespace,
            nameguard=nameguard,
            comments_re=comments_re,
            eol_comments_re=eol_comments_re,
            ignorecase=ignorecase,
            left_recursion=left_recursion,
            parseinfo=parseinfo,
            keywords=keywords,
            namechars=namechars,
            tokenizercls=tokenizercls,
            **kwargs
        )

    @tatsumasu()
    def _start_(self):  # noqa
        self._program_()
        self._check_eof()

    @tatsumasu()
    def _program_(self):  # noqa

        def block0():
            with self._choice():
                with self._option():
                    self._rule_()
                with self._option():
                    self._query_()
                self._error('expecting one of: normal_rule probability query query( rule')
        self._closure(block0)

    @tatsumasu()
    def _rule_(self):  # noqa
        with self._optional():
            self._probability_()
            self._token('::')
        self._normal_rule_()
        self._token('.')

    @tatsumasu()
    def _normal_rule_(self):  # noqa
        self._atom_()
        with self._optional():
            self._token(':-')
            self._body_()

    @tatsumasu()
    def _body_(self):  # noqa
        self._atom_()

        def block0():
            self._token(',')
            self._atom_()
        self._closure(block0)

    @tatsumasu()
    def _atom_(self):  # noqa
        self._pattern('[a-z]([a-zA-Z0-9_])*')
        with self._optional():
            self._token('(')
            self._input_()
            self._token(')')

    @tatsumasu()
    def _input_(self):  # noqa
        self._term_()

        def block0():
            self._token(',')
            self._term_()
        self._closure(block0)

    @tatsumasu()
    def _term_(self):  # noqa
        self._pattern('[a-zA-Z0-9\'"]*')

    @tatsumasu()
    def _probability_(self):  # noqa
        self._pattern('[^:]*')

    @tatsumasu()
    def _query_(self):  # noqa
        self._token('query(')
        self._atom_()
        self._token(').')


def main(filename, start=None, **kwargs):
    if start is None:
        start = 'start'
    if not filename or filename == '-':
        text = sys.stdin.read()
    else:
        with open(filename) as f:
            text = f.read()
    parser = ProblogParser()
    return parser.parse(text, rule_name=start, filename=filename, semantics = ProblogSemantics())


if __name__ == '__main__':
    import json
    from tatsu.util import asjson

    program = generic_main(main, ProblogParser, name='Problog')
    for rule in program:
        print(rule.asp_string())
