<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>aspmc.programs.program API documentation</title>
<meta name="description" content="Program module providing the progam class with cycle breaking methods and clark completion(s)." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>aspmc.programs.program</code></h1>
</header>
<section id="section-intro">
<p>Program module providing the progam class with cycle breaking methods and clark completion(s).</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3

&#34;&#34;&#34;
Program module providing the progam class with cycle breaking methods and clark completion(s).
&#34;&#34;&#34;

from platform import node
import networkx as nx
import os
import logging
import numpy as np
import time
import math


from aspmc.parsing.clingoparser.clingoext import ClingoRule

from aspmc.graph.hypergraph import Hypergraph
import aspmc.graph.treedecomposition as treedecomposition

from aspmc.compile.cnf import CNF

from aspmc.parsing.clingoparser.clingoext import Control
import aspmc.programs.backdoor as backdoor
import aspmc.programs.grounder as grounder

import subprocess

import inspect 

src_path = os.path.abspath(os.path.realpath(inspect.getfile(inspect.currentframe())))
src_path = os.path.realpath(os.path.join(src_path, &#39;../../external&#39;))

import aspmc.config as config

from aspmc.programs.naming import *

logger = logging.getLogger(&#34;aspmc&#34;)

class UnsupportedException(Exception):
    &#39;&#39;&#39;raise this when the program relies on features that are not supported yet&#39;&#39;&#39;

class Rule(object):
    &#34;&#34;&#34;A class for rules.

    Implements a custom `__repr__` method.

    Args:        
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.

    Attributes:
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.
    &#34;&#34;&#34;
    def __init__(self, head, body):
        self.head = head
        self.body = body

    def __hash__(self):
        return hash((tuple(self.head), tuple(self.body)))

    def __eq__(self, other):
        if not isinstance(other, type(self)): 
            return NotImplemented
        return self.head == other.head and self.body == other.body

    def __repr__(self):
        return &#34;; &#34;.join([str(a) for a in self.head]) + &#34;:- &#34; + &#34;, &#34;.join([ (&#34;not &#34; if b &lt; 0 else &#34;&#34;) + str(abs(b)) for b in self.body]) 

class Program(object):
    &#34;&#34;&#34;A base class for programs. No weights, no queries this is only for getting a cnf representation of the program.

    Allowed features are: 

    * facts
    * normal rules
    * unconditional choice constraints
    * constraints

    The cnf is generated by first doing Tp-Unfolding and then applying a Clark completion to the resulting tight program. 

    Args:
        program_str (:obj:`string`): A string containing a part of the program in ASP syntax. 
            May be the empty string.
        program_files (:obj:`list`): A list of string that are paths to files which contain programs in ASP syntax 
            that should be included. May be an empty list.
        clingo_control (:obj:`Control`): A clingo control object that contains parts of the program. 
            Must already be ground if no non-empty `program_str` or `program_files` are given.
    &#34;&#34;&#34;
    def __init__(self, clingo_control = Control(), program_str = &#34;&#34;, program_files = [], smodels = False):
        # the variable counter
        self._max = 0
        self._nameMap = {}
        # store the clauses here
        self._cnf = CNF()
        # remember which variables are guesses, which are derived, and which are copies of derived atoms.
        self._guess = set()
        self._deriv = set()
        self._copies = {}
        # remember possible auxilliary variables that clingo introduced
        self._auxilliary = set()
        # the list containing all the rules (except guesses)
        self._program = []
        # remember which atoms have to satisfy an exactly one of constraint
        self._exactlyOneOf = set()
        # the tree decomposition of the program
        self._td = None
        if not smodels:
            if (len(program_str) &gt; 0 or len(program_files) &gt; 0):
                grounder.ground(clingo_control, program_str = program_str, program_files = program_files)
            self._normalize(clingo_control)
        else:
            if (len(program_str) &gt; 0 and len(program_files) &gt; 0) or len(program_files) &gt; 1:
                print(program_files, program_str)
                raise UnsupportedException(&#34;When instantiating a program from smodels format only one file or a program string may be given.&#34;)
            self._parse_smodels(program_str = program_str, program_files = program_files)

    def _parse_smodels(self, program_str = &#34;&#34;, program_files = []):
        if len(program_str) &gt; 0:
            lines = program_str.split(&#39;\n&#39;)
        else:
            with open(program_files[0], &#39;r&#39;) as in_file:
                lines = [ line[:-1] for line in in_file.readlines() ]

        for i in range(len(lines)):
            line = [ int(v) for v in lines[i].split(&#39; &#39;) ]
            if line[0] == 0:
                break
            elif line[0] == 1:
                head = [ line[1] ]
                nr_lit = line[2]
                nr_neg = line[3]
                body = line[4:4+nr_lit]
                self._max = max(head[0], self._max, max(body, default=0))
                for i in range(nr_neg):
                    body[i] *= -1
                self._program.append(Rule(head = head, body = body))
                self._deriv.add(head[0])
            elif line[0] == 3:
                if line[1] &gt; 1:
                    raise UnsupportedException(&#34;Currently no choice rules with more than one atom in the head are supported.&#34;)
                elif line[1] &gt; 0 and line[line[1] + 1] &gt; 0:
                    raise UnsupportedException(&#34;Currently conditional choice rules are not supported.&#34;)
                if line[1] == 1:
                    self._guess.add(line[2])
                    self._max = max(self._max(line[2]))
            else:
                raise UnsupportedException(f&#34;Unsupported rule type {line[0]}.&#34;)

        assert(len(self._deriv.intersection(self._guess)) == 0)
        ctr = i
        for i in range(ctr + 1, len(lines)):
            line = lines[i].split(&#39; &#39;)
            if line[0] == &#39;0&#39;:
                break
            self._nameMap[int(line[0])] = line[1]
            self._max = max(self._max, int(line[0]))
        ctr = i
        assert(lines[ctr + 1] == &#34;B+&#34;)
        for i in range(ctr + 2, len(lines)):
            if lines[i] == &#39;0&#39;:
                break
            self._program.append(Rule(head = [], body = [ -int(lines[i]) ]))
        ctr = i
        assert(lines[ctr + 1] == &#34;B-&#34;)
        for i in range(ctr + 2, len(lines)):
            if lines[i] == &#39;0&#39;:
                break
            self._program.append(Rule(head = [], body = [ int(lines[i]) ]))
        ctr = i
        if lines[ctr + 1] == &#34;E&#34;:
            for i in range(ctr + 2, len(lines)):
                if lines[i] == &#39;0&#39;:
                    break
                self._guess.add(int(lines[i]))
                
        self._deriv = set(range(1, self._max + 1))
        self._deriv.difference_update(self._guess)
        for v in self._deriv:
            if v not in self._nameMap:
                self._nameMap[v] = f&#34;projected_away({v})&#34;

    def _remove_tautologies(self, clingo_control):
        tmp = []
        for o in clingo_control.ground_program.objects:
            if isinstance(o, ClingoRule) and set(o.head).intersection(set(o.body)) == set():
                tmp.append(o)
        return tmp

    def _normalize(self, clingo_control):
        program = self._remove_tautologies(clingo_control)
        _atomToVertex = {} # the tree decomposition solver wants succinct numbering of vertices / no holes

        symbol_map = {}
        for sym in clingo_control.symbolic_atoms:
            symbol_map[sym.literal] = str(sym.symbol)
        for o in program:
            if isinstance(o, ClingoRule):
                if len(o.head) &gt; 1 and o.choice:
                    raise UnsupportedException(&#34;Currently no choice rules with more than one atom in the head are supported.&#34;)
                if len(o.body) &gt; 0 and o.choice:
                    raise UnsupportedException(&#34;Currently conditional choice rules are not supported.&#34;)
                o.atoms = set(o.head)
                o.atoms.update(tuple(map(abs, o.body)))
                # if we have the falsum rule we want to replace it with two rules
                if not o.atoms:
                    a = self._new_var(&#34;unsat&#34;)
                    orig_max = max( v for v in symbol_map.keys() ) + 1
                    _atomToVertex[orig_max] = a
                    o.atoms.add(orig_max)
                    o.head = [orig_max]
                    o.body = [-orig_max]
                    o.choice = False
                self._program.append(o)
                for a in o.atoms.difference(_atomToVertex):     # add mapping for atom not yet mapped
                    if a in symbol_map:
                        _atomToVertex[a] = self._new_var(symbol_map[a])
                    else:
                        aux_var = self._new_var(f&#34;projected_away({a})&#34;)
                        _atomToVertex[a] = aux_var
                        self._auxilliary.add(aux_var)

        trans_prog = set()
        self._deriv = set(range(1,self._max + 1))
        for r in self._program:
            if r.choice: 
                guess = [ _atomToVertex[r.head[0]] ]
                self._deriv.difference_update(guess)
                self._guess.update(guess)
            elif len(r.head) &gt; 1:
                guess = [ _atomToVertex[x] for x in r.head ]
                self._deriv.difference_update(guess)
                self._guess.update(guess)
                self._exactlyOneOf.add(frozenset(guess))
            else:
                head = list(map(lambda x: _atomToVertex[x], r.head))
                body = list(map(lambda x: _atomToVertex[abs(x)]*(1 if x &gt; 0 else -1), r.body))
                trans_prog.add(Rule(head,body))
        self._program = trans_prog

    def _new_var(self, name):
        self._max += 1
        self._nameMap[self._max] = name if name != &#34;&#34; else str(self._max)
        return self._max

    def _copy_var(self, var):
        if &#34;(&#34; in self._nameMap[var]:
            idx = self._nameMap[var].index(&#34;(&#34;)
            inputs = self._nameMap[var][idx:]
        else:
            inputs = &#34;&#34;
        if &#34;_copy_&#34; in self._nameMap[var]:
            idx = self._nameMap[var].index(&#34;_copy_&#34;)
            pred = self._nameMap[var][:idx]
        else:
            pred = self._nameMap[var]
            if &#34;(&#34; in pred:
                idx = pred.index(&#34;(&#34;)
                pred = pred[:idx]
            if pred+inputs not in self._copies:
                self._copies[pred+inputs] = [var]
        cnt = len(self._copies[pred+inputs])
        name = pred + &#34;_copy_&#34; + str(cnt) + inputs
        nv = self._new_var(name)
        self._copies[pred+inputs].append(nv)
        return nv

    def _internal_name(self, var):
        return self._nameMap[var]
    
    def _external_name(self, var):
        name = self._nameMap[var]
        # replace internal names with external names so we can parse programs that we print without errors
        for (internal, external) in conversions.items():
            name = name.replace(internal, external)
        return name

    def _computeComponents(self):
        self.dep = nx.DiGraph()
        self.dep.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            for a in r.head:
                for b in r.body:
                    if b &gt; 0:
                        self.dep.add_edge(b, a)
        comp = nx.algorithms.strongly_connected_components(self.dep)
        self._components = list(comp)
        self._condensation = nx.algorithms.condensation(self.dep, self._components)
        &#34;&#34;&#34;
        import matplotlib.pyplot as plt
        from networkx.drawing.nx_pydot import graphviz_layout
        labels = { node : str(node) for node in range(1, self._max + 1) }
        node_to_comp = {}
        for comp in self._components:
            for v in comp:
                node_to_comp[v] = comp
        red_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] == node_to_comp[u] ]
        edge_colours = [&#39;black&#39; if not edge in red_edges else &#39;red&#39; for edge in self.dep.edges()]
        black_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] != node_to_comp[u] ]
        pos = graphviz_layout(self.dep, prog=&#34;dot&#34;)
        nx.draw(self.dep, pos)
        nx.draw_networkx_labels(self.dep, pos, labels)
        nx.draw_networkx_edges(self.dep, pos, edgelist=red_edges, edge_color=&#39;r&#39;, arrows=True)
        nx.draw_networkx_edges(self.dep, pos, edgelist=black_edges, arrows=True)
        plt.axis(&#34;off&#34;)
        plt.show()
        &#34;&#34;&#34;

    def treeprocess(self):
        &#34;&#34;&#34;Applies tree processing to the program. 
        
        This means that if there is a part of the dependency graph that is a tree and
        only has one connection to the rest of the dependency graph, then it will be processed.

        Results in one copy for each atom in the tree.

        Returns:
            None        
        &#34;&#34;&#34;
        ins = {}
        outs = {}
        for a in self._deriv:
            ins[a] = set()
            outs[a] = set()

        for a in self._guess:
            ins[a] = set()
            outs[a] = set()

        for r in self._program:
            for a in r.head:
                ins[a].add(r)
            for b in r.body:
                if b &gt; 0:
                    outs[b].add(r)
        ts = nx.topological_sort(self._condensation)
        ancs = {}
        decs = {}
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            for v in comp:
                ancs[v] = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
                decs[v] = set([vp[1] for vp in self.dep.out_edges(nbunch=v) if vp[1] in comp])
        q = set([v for v in ancs.keys() if len(ancs[v]) == 1 and len(decs[v]) == 1 and list(ancs[v])[0] == list(decs[v])[0]])
        while not len(q) == 0:
            old_v = q.pop()
            if len(ancs[old_v]) == 0:
                continue
            new_v = self._copy_var(old_v)
            self._deriv.add(new_v)
            ins[new_v] = set()
            outs[new_v] = set()
            anc = ancs[old_v].pop()
            ancs[anc].remove(old_v)
            decs[anc].remove(old_v)
            if len(ancs[anc]) == 1 and len(decs[anc]) == 1 and list(ancs[anc])[0] == list(decs[anc])[0]:
                q.add(anc)

            # this contains all rules that do not use anc to derive v
            to_rem = ins[old_v].difference(outs[anc])
            # this contains all rules that use anc to derive v
            # we just keep them as they are
            ins[old_v] = ins[old_v].intersection(outs[anc])
            # any rule that does not use anc to derive v can now only derive new_v
            for r in to_rem:
                head = [b if b != old_v else new_v for b in r.head]
                new_r = Rule(head,r.body)
                ins[new_v].add(new_r)
                for b in r.body:
                    if b &gt; 0:
                        outs[b].remove(r)
                        outs[b].add(new_r)

            # this contains all rules that use v and derive anc
            to_rem = outs[old_v].intersection(ins[anc])
            # this contains all rules that use v and do not derive anc
            # we just keep them as they are
            outs[old_v] = outs[old_v].difference(ins[anc])
            # any rule that uses v to derive anc must use new_v
            for r in to_rem:
                body = [ (b if b != old_v else new_v) for b in r.body]
                new_r = Rule(r.head,body)
                for b in r.head:
                    ins[b].remove(r)
                    ins[b].add(new_r)
                for b in r.body:
                    if b &gt; 0:
                        if b != old_v:
                            outs[abs(b)].remove(r)
                            outs[abs(b)].add(new_r)
                        else:
                            outs[new_v].add(new_r)
            new_r = Rule([old_v], [new_v])
            ins[old_v].add(new_r)
            outs[new_v].add(new_r)
        # only keep the constraints
        self._program = [r for r in self._program if len(r.head) == 0]
        # add all the other rules
        for a in ins.keys():
            self._program.extend(ins[a])


    def _write_scc(self, comp):
        res = &#34;&#34;
        for v in comp:
            res += f&#34;p({v}).\n&#34;
            ancs = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            for vp in ancs:
                res += f&#34;edge({vp},{v}).\n&#34;
        return res

    def _compute_backdoor_clingo(self, idx, timeout = 30.0):
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        program_str = &#34;\n&#34;.join(f&#34;{{abs({v})}}.&#34; for v in comp) + &#34;\n&#34;
        program_str += &#34;:~ abs(X). [1,X]\n&#34;
        program_str += &#34;ok(X) :- abs(X).\n&#34;
        for v in comp:
            ancs = list(set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp] + [vp[0] for vp in self.dep.out_edges(nbunch=v) if vp[0] in comp]))
            for i in range(len(ancs)):
                program_str += f&#34;ok({v}) :- {&#39;,&#39;.join(f&#39;ok({vp})&#39; for vp in ancs[:i] + ancs[i+1:])}.\n&#34;
        program_str += &#34;\n&#34;.join(f&#34;:- not ok({v}).&#34; for v in comp) + &#34;\n&#34;
        program_str += &#34;#show abs/1.&#34;
        c = backdoor.ClingoControl(program_str)
        res = c.get_backdoor(None, timeout = timeout)[2][0]
        return res

    def _compute_backdoor_fvs(self, idx, timeout = 30.0, approximate = False):
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        edges = {}
        for v in comp:
            ancs = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            for vp in ancs:
                if vp &gt; v:
                    if v not in edges:
                        edges[v] = set()
                    edges[v].add(vp)
                else:
                    if vp not in edges:
                        edges[vp] = set()
                    edges[vp].add(v)
        graph = &#34;&#34;
        for v in edges.keys():
            for vp in edges[v]:
                graph += f&#34;{v} {vp}\n&#34;
        if not approximate:
            q = subprocess.Popen([os.path.join(src_path, &#34;fvs/src/build/FeedbackVertexSet&#34;)], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            output, err = q.communicate(input=graph.encode(), timeout = float(config.config[&#34;backdoort&#34;]))
        else:
            q = subprocess.Popen([os.path.join(src_path, &#34;fvs/src/build/FeedbackVertexSet&#34;), &#34;Appx&#34;], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            output, err = q.communicate(input=graph.encode())
        res = [ int(v) for v in output.decode().split()[1:] ]
        return res

    def _compute_backdoor(self, idx):
        start = time.time()
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        try:
            if config.config[&#34;backdoors&#34;] == &#34;fvs&#34;:
                res = self._compute_backdoor_fvs(idx, timeout = float(config.config[&#34;backdoort&#34;]), approximate = False)
            elif config.config[&#34;backdoors&#34;] == &#34;clingo&#34;:
                res = self._compute_backdoor_clingo(idx, timeout = float(config.config[&#34;backdoort&#34;]))
        except (subprocess.TimeoutExpired,IndexError):
            logger.warning(f&#34;Optimal backdoor computation failed, switching to approximation.&#34;)
            res = self._compute_backdoor_fvs(idx, timeout = float(config.config[&#34;backdoort&#34;]), approximate = True)
        if False:
            import matplotlib.pyplot as plt
            from networkx.drawing.nx_pydot import graphviz_layout
            labels = { node : self._external_name(node) for node in comp }
            local_dep = self.dep.subgraph(comp)
            pos = graphviz_layout(local_dep, prog=&#34;neato&#34;)
            values = [ 1.0 if node in res else 0.0 for node in local_dep.nodes()]
            nx.draw(local_dep, pos, cmap=plt.get_cmap(&#39;viridis&#39;), node_color=values)
            nx.draw_networkx_labels(local_dep, pos, labels)
            plt.tight_layout()
            plt.axis(&#34;off&#34;)
            plt.show()
        logger.debug(&#34;backdoor comp: &#34; + str(len(comp)))
        logger.debug(&#34;backdoor res: &#34; + str(len(res)))
        logger.debug(f&#34;backdoor time: {time.time() - start}&#34;)
        return res

    def _backdoor_process(self, comp, backdoor):
        comp = set(comp)
        backdoor = set(backdoor)

        toRemove = set()
        ins = {}
        for a in comp:
            ins[a] = set()
        for r in self._program:
            for a in r.head:
                if a in comp:
                    ins[a].add(r)
                    toRemove.add(r)

        copies = {}
        for a in comp:
            copies[a] = {}
            copies[a][len(backdoor)] = a

        def getAtom(atom, i):
            # negated atoms are kept as they are
            if atom &lt; 0:
                return atom
            # atoms that are not from this component are input atoms and should stay the same
            if atom not in comp:
                return atom
            if i &lt; 0:
                print(&#34;this should not happen&#34;)
                exit(-1)
            if atom not in copies:
                print(&#34;this should not happen&#34;)
                exit(-1)
            if i not in copies[atom]:
                copies[atom][i] = self._copy_var(atom)
                self._deriv.add(copies[atom][i])
            return copies[atom][i]

        toAdd = set()
        for a in backdoor:
            for i in range(1,len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 1:
                        # in the first iteration we do not add rules that use atoms from the backdoor
                        add = True
                        for x in r.body:
                            if x &gt; 0 and x in backdoor:
                                add = False
                    else:
                        # in all but the first iteration we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x &gt; 0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i - 1) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i &gt; 1:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        for a in comp.difference(backdoor):
            for i in range(len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 0:
                        # in the first iteration we only add rules that only use atoms from outside 
                        add = True
                        for x in r.body:
                            if x &gt; 0 and x in backdoor:
                                add = False
                    else:
                        # in all other iterations we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x &gt;  0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i &gt; 0:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        self._program = [r for r in self._program if r not in toRemove]
        self._program += list(toAdd)
        
        
    def tpUnfold(self):
        &#34;&#34;&#34;Applies Tp-Unfolding to the program. 
        
        Applies a variant to be precise by first doing treeprocessing
        and then Tp-Unfolding as this can be a bit better.

        Returns:
            None        
        &#34;&#34;&#34;
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                backdoor = self._compute_backdoor(t)
                # if the backdoor needs more than half the atoms it is better if we use all the atoms as the backdoor
                # this is because treeprocessing has another factor*2 and backdoor*2 &gt; comp
                backdoor = comp if len(backdoor) &gt; len(comp)/2 else backdoor
                self._backdoor_process(comp, backdoor)
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                logger.error(&#34;Cycle breaking failed: the dependency graph still has a non-trivial SCC&#34;)
                exit(-1)

    def binary_cycle_breaking(self, local = False):
        if self._td is None and local:
            self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        self._computeComponents()
        # here we remember the new rules
        new_rules = []
        # maps a node t to a set of rules that need to be considered in t
        # it actually suffices if every rule is considered only once in the entire td..
        rules = {}
        # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
        lessThan = {}
        # remember which atoms we used for the bits 
        bits = {}
        if local:
            for t in self._td.bag_iter():
                bits[t] = {}
                tmp_vert = t.vertices.copy()
                while not len(tmp_vert) == 0:
                    cur = tmp_vert.pop()
                    if cur in self._condensation.graph[&#34;mapping&#34;]:
                        # otherwise cur does not occur positively
                        comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                        comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                        tmp_vert.difference_update(comp)
                        both = t.vertices.intersection(comp)
                        count = math.ceil(math.log(len(both),2))
                        for a in both:
                            bits[t][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},{t.idx},{i})&#34;) for i in range(count) ]
                            self._guess.update(bits[t][a])
        else:
            bits[None] = {}
            for comp in self._components:
                count = math.ceil(math.log(len(comp),2))
                for a in comp:
                    bits[None][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},none,{i})&#34;) for i in range(count)]
                    self._guess.update(bits[None][a])

        if local:
            # temporary copy of the program, will be empty after the first pass
            program = list(self._program)
            # first td pass: determine rules 
            for t in self._td.bag_iter():
                # take the rules we need and remove them
                rules[t] = [r for r in program if set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
                program = [r for r in program if not set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
        else: 
            rules[None] = list(self._program)

        # a subroutine to generate x &lt; x&#39;
        def generateLessThan(x, xp, local = False, node = None):
            assert(node is not None or not local)
            # setup and check if this has already been handled
            if not (x,xp,node) in lessThan:
                lessThan[(x,xp,node)] = self._new_var(f&#34;less_than({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)})&#34;)
                self._deriv.add(lessThan[(x,xp,node)])
            else:
                return lessThan[(x,xp,node)]

            # check if x and xp are in differens components
            xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
            xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
            if xs_comp != xps_comp:
                # determine which is in the higher component
                if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                    new_rules.append(Rule([lessThan[(x,xp,node)]],[]))
                elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                    new_rules.append(Rule([],[lessThan[(x,xp,node)]]))
                else: # there is no connection between these at all. should not occur.
                    logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                    exit(1)
                return lessThan[(x,xp,node)]

            # x and xp are in the same component 
            # obtain the bits and their number
            count = len(bits[node][x])
            x_bits = bits[node][x]
            xp_bits = bits[node][xp]

            # remember all the disjuncts here
            head = [ lessThan[(x,xp,node)] ]
            for i in range(count):
                body = [ xp_bits[i], -x_bits[i] ]
                for j in range(i + 1, count):
                    andVar = self._new_var(f&#34;less_than_bin({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)},{i},{j})&#34;)
                    self._deriv.add(andVar)
                    body.append(-andVar)
                    new_rules.append(Rule([andVar], [-xp_bits[j], x_bits[j]]))
                new_rules.append(Rule(head, body))
            return lessThan[(x,xp,node)]

        if local:
            # second td pass: use rules to generate the reduction
            for t in self._td.bag_iter():
                # generate (2), i.e. the constraints that maintain the inequalities between nodes
                for tp in t.children:
                    relevant = tp.vertices.intersection(t.vertices)
                    rel_cp = relevant.copy()
                    while len(rel_cp) &gt; 0:
                        cur = rel_cp.pop()
                        comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                        comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                        both = relevant.intersection(comp)
                        for x in both:
                            if x == cur:
                                continue
                            t_atom = generateLessThan(x, cur, local = local, node = t)
                            tp_atom = generateLessThan(x, cur, local = local, node = tp)
                            new_rules.append(Rule([],[t_atom, -tp_atom]))
                            new_rules.append(Rule([],[-t_atom, tp_atom]))
                                
                
                # add the order constraints to the rules in the current node
                for r in rules[t]:
                    if len(r.head) &gt; 0:
                        to_add = []
                        head = r.head[0]
                        for a in r.body:
                            if a &gt; 0:
                                to_add.append(generateLessThan(a, head, local = local, node = t))
                        new_rules.append(Rule([], [-head] + r.body))
                        r.body += to_add
                    new_rules.append(r)
        else:
            # add the order constraints to the rules in the current node
            for r in rules[None]:
                if len(r.head) &gt; 0:
                    to_add = []
                    head = r.head[0]
                    for a in r.body:
                        if a &gt; 0:
                            to_add.append(generateLessThan(a, head, local = local, node = None))
                    new_rules.append(Rule([], [-head] + r.body))
                    r.body += to_add
                new_rules.append(r)
        self._program = new_rules

    
     

    def less_than_cycle_breaking(self, opt = True):
        self._computeComponents()
        # here we remember the new rules
        new_rules = []
        # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
        lessThan = {}

        # a subroutine to generate x &lt; x&#39;
        def getLessThan(x, xp):
            negated = x &gt; xp
            if negated:
                x,xp = xp,x
            # setup and check if this has already been handled
            if not (x,xp) in lessThan:
                lessThan[(x,xp)] = self._new_var(f&#34;less_than({x},{xp})&#34;)
                # add the atoms as guesses
                self._guess.add(lessThan[(x,xp)])
            else:
                return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

            # check if x and xp are in differens components
            xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
            xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
            if xs_comp != xps_comp:
                # determine which is in the higher component
                if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                    new_rules.append(Rule([], [-lessThan[(x,xp)]]))
                elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                    new_rules.append(Rule([], [lessThan[(x,xp)]]))
                else: # there is no connection between these at all. should not occur.
                    logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                    exit(1)

            return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                # antisymmetry and connexity are true automatically
                if opt:
                    x_values = self._compute_backdoor(t)
                else:
                    x_values = comp
                # transitivity
                for x in x_values:
                    for y in comp:
                        if x == y:
                            continue
                        if opt:
                            z_values = self.dep.successors(y)
                        else:
                            z_values = comp
                        for z in z_values:
                            if y != z and x != z:
                                new_rules.append(Rule([], [getLessThan(x,y), getLessThan(y,z), -getLessThan(x,z)]))
                        
        
        # add lessThan atoms to break the cycles reduction
        for r in self._program:
            if len(r.head) &gt; 0:
                to_add = []
                head = r.head[0]
                for a in r.body:
                    if a &gt; 0:
                        to_add.append(getLessThan(a, head))
                new_rules.append(Rule([], [-head] + r.body))
                r.body += to_add
            new_rules.append(r)
        self._program = new_rules



    def _decomposeGraph(self, solver = &#34;flow-cutter&#34;, timeout = &#34;-1&#34;):            
        self._graph = Hypergraph()
        self._graph.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            atoms = set(r.head)
            atoms.update(tuple(map(abs, r.body)))
            self._graph.add_edge(atoms)
        self._td = treedecomposition.from_hypergraph(self._graph, solver = solver, timeout = timeout)

    def clark_completion(self):
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Does not use tree decomposition guidance to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars

        perAtom = {}
        for a in self._deriv:
            perAtom[a] = []

        for r in self._program:
            for a in r.head:
                perAtom[a].append(r)

        for head in self._deriv:
            ors = []
            for r in perAtom[head]:
                ors.append(aux_var())
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ors[-1]] + ands)
                for at in ands:
                    self._cnf.clauses.append([-ors[-1], -at])
            self._cnf.clauses.append([-head] + [o for o in ors])
            for o in ors:
                self._cnf.clauses.append([head, -o])

        # handle the constraints
        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])

        # handle the guesses
        for r in self._exactlyOneOf:
            # at least one
            self._cnf.clauses.append(list(r))
            # at most one
            for v in r:
                for vp in r:
                    if v &lt; vp:
                        self._cnf.clauses.append([-v, -vp])
                            
        self._finalize_cnf()

    def td_guided_clark_completion(self):        
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on the &#34;ors&#34; to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars
        
        self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        logger.info(f&#34;Tree Decomposition #bags: {self._td.bags} unfolded treewidth: {self._td.width} #vertices: {self._td.vertices}&#34;)
        # at which td node to handle each rule
        rules = {}
        # at which td node each variable occurs last
        last = {}
        idx = 0
        td_idx = list(self._td)
        for t in self._td.bag_iter():
            for a in t.vertices:
                last[a] = idx
            t.idx = idx
            idx += 1
            rules[t] = []

        for r in self._program:
            for a in r.head:
                r.proven = aux_var()
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ r.proven ] + ands)
                for at in ands:
                    self._cnf.clauses.append([ -r.proven, -at ])
            idx = min([ last[abs(b)] for b in r.body + r.head ])
            rules[self._td.get_bag(td_idx[idx])].append(r)

        # how many rules have we used and what is the last used variable
        unfinished = {}
        for t in self._td.bag_iter():
            unfinished[t] = {}
            t.vertices = set(t.vertices)
            to_handle = {}
            for a in t.vertices:
                to_handle[a] = []
            for tp in t.children:
                removed = tp.vertices.difference(t.vertices)
                for a in removed:
                    if a in self._deriv:
                        if a in unfinished[tp]:
                            final = unfinished[tp].pop(a)
                            self._cnf.clauses.append([-a, final])
                            self._cnf.clauses.append([a, -final])
                        else: 
                            self._cnf.clauses.append([-a])
                rest = tp.vertices.intersection(t.vertices)
                for a in rest:
                    if a in unfinished[tp]:
                        to_handle[a].append(unfinished[tp][a])

            # take the rules we need
            for r in rules[t]:
                for a in r.head:
                    to_handle[a].append(r.proven)

            # handle all the rules we have gathered
            for a in t.vertices:
                if len(to_handle[a]) &gt; 1:
                    new_last = aux_var()
                    self._cnf.clauses.append([-new_last] + to_handle[a])
                    for at in to_handle[a]:
                        self._cnf.clauses.append([new_last, -at])
                    unfinished[t][a] = new_last
                elif len(to_handle[a]) == 1:
                    unfinished[t][a] = to_handle[a][0]

        for a in self._td.get_root().vertices:
            if a in self._deriv:
                if a in unfinished[self._td.get_root()]:
                    final = unfinished[self._td.get_root()].pop(a)
                    self._cnf.clauses.append([-a, final])
                    self._cnf.clauses.append([a, -final])
                else: 
                    self._cnf.clauses.append([-a])

        # handle the constraints
        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])

       # handle the guesses
        for r in self._exactlyOneOf:
            # at least one
            self._cnf.clauses.append(list(r))
            # at most one
            for v in r:
                for vp in r:
                    if v &lt; vp:
                        self._cnf.clauses.append([-v, -vp])

        self._finalize_cnf()


    def td_guided_both_clark_completion(self, adaptive = False, latest = True): 
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on both the &#34;ands&#34; and the &#34;ors&#34;
        to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars

        # remember whats an and, whats an or and whats a constraint
        # also include the guesses, which guess exactly one of their inputs to be true
        OR = 0
        AND = 1
        CON = 2
        GUESS = 3
        INPUT = 4
        nodes = { a : (OR, set()) for a in self._deriv }

        exactly_one_to_var = {}
        for a in self._exactlyOneOf:
            exactly_one_to_var[a] = aux_var()
            nodes[exactly_one_to_var[a]] = (GUESS, set(a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        if not latest:
            seen = set()
            facts = set([ r.head[0] for r in self._program if len(r.body) == 0 ])
            for f in facts:
                self._cnf.clauses.append([f])
            seen.update(facts)
        
        if not latest:
            remaining = [ r for r in self._program if len(r.head) == 0 or r.head[0] not in facts ]
        else:
            remaining = self._program
        for r in remaining:
            r.proven = aux_var()
            if len(r.head) != 0:
                nodes[r.proven] = (AND, set(r.body))
                nodes[abs(r.head[0])][1].add(r.proven)
                if not latest:
                    seen.add(r.head[0])
            else:
                nodes[r.proven] = (CON, set([ -atom for atom in r.body ]))

        if not latest:
            # handle the atoms that do not occur in the head of any rule
            falses = [ a for a in self._deriv if a not in seen and nodes[a][0] == OR and len(nodes[a][1]) == 0 ]
            for f in falses:
                self._cnf.clauses.append([-f])

        # set up the and/or graph
        graph = nx.Graph()
        graph.add_nodes_from(range(1, self._cnf.nr_vars + 1))
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(atom, r.proven)
                    if adaptive:
                        graph.add_edge(atom + self._cnf.nr_vars, r.proven)
                for atom in r.body:
                    graph.add_edge(r.proven, abs(atom))
                    if adaptive:
                        graph.add_edge(r.proven + self._cnf.nr_vars, abs(atom))
        
        for a in self._exactlyOneOf:
            for atom in a:
                graph.add_edge(exactly_one_to_var[a], atom)
                if adaptive:
                    graph.add_edge(exactly_one_to_var[a] + self._cnf.nr_vars, atom)


        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        if adaptive:
            td.remove(set(range(self._cnf.nr_vars + 1, 2*self._cnf.nr_vars + 1)))
            td.vertices = self._cnf.nr_vars 
        logger.info(f&#34;Tree Decomposition #bags: {td.bags} unfolded treewidth: {td.width} #vertices: {td.vertices}&#34;)

        
        if latest:
            # at which td node each variable occurs last
            last = {}
            idx = 0
            for t in td.bag_iter():
                for a in t.vertices:
                    last[a] = idx
                t.idx = idx
                idx += 1
        
        # remember per bag which nodes have which partial result
        unfinished = {}
        # handle the bags in dfs order
        for t in td.bag_iter():
            unfinished[t] = {}
            # first take care of what we got from the children
            for tp in t.children:
                for atom in unfinished[tp]:
                    if atom not in unfinished[t]:
                        unfinished[t][atom] = unfinished[tp][atom]
                    else:
                        if len(unfinished[tp][atom]) == 1:
                            first_lit = unfinished[tp][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            first_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigAnd)                  
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                            elif node_type == GUESS:
                                # remember in first_lit, whether one of the unfinished atoms is true
                                bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[tp][atom]:
                                    for vp in unfinished[tp][atom]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        if len(unfinished[t][atom]) == 1:
                            second_lit = unfinished[t][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            second_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ second_lit, -v ])
                            elif node_type == GUESS:
                                # remember in second_lit, whether one of the unfinished atoms is true
                                bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ second_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][atom]:
                                    for vp in unfinished[t][atom]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        unfinished[t][atom] = set([first_lit, second_lit])
                        
            if not latest:
                # then take care of the current bag
                for a in t.vertices:
                    node_type, inputs = nodes[a]
                    todo_new = set([ atom for atom in inputs if abs(atom) in t.vertices ])
                    if len(todo_new) == 0:
                        continue
                    inputs.difference_update(todo_new)
                    if a not in unfinished[t]:
                        unfinished[t][a] = todo_new
                    else:
                        if len(unfinished[t][a]) == 1:
                            first_lit = unfinished[t][a].pop()
                        else:
                            first_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                            elif node_type == GUESS:
                                # remember in first_lit, whether one of the unfinished atoms is true
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][a]:
                                    for vp in unfinished[t][a]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        if len(todo_new) == 1:
                            second_lit = todo_new.pop()
                        else:
                            second_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                                self._cnf.clauses.append(bigAnd)
                                for v in todo_new:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                            elif node_type == GUESS:
                                # remember in second_lit, whether one of the unfinished atoms is true
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in todo_new:
                                    for vp in todo_new:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        unfinished[t][a] = set([first_lit, second_lit])

                
                # check which nodes are completely done and finalize them
                new_unfinished = {}
                for a in unfinished[t]:
                    if a in t.vertices: # if the variable is still there, we keep it
                        new_unfinished[a] = unfinished[t][a]
                    else: # otherwise we finalize the node
                        node_type = nodes[a][0]
                        if node_type == AND:
                            bigAnd = [ a ] + [ -v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigAnd)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ -a, v ])
                        elif node_type == OR:
                            bigOr = [ -a ] + [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ a, -v ])
                        elif node_type == CON:
                            bigOr = [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            self._cnf.clauses.append([-a])
                        elif node_type == GUESS:
                            # make sure that at least one of the unfinished atoms is true
                            bigOr = [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            # make sure that not more than one of the unfinished atoms is true
                            for v in unfinished[t][a]:
                                for vp in unfinished[t][a]:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])
                            self._cnf.clauses.append([-a])

                unfinished[t] = new_unfinished
            else:
                # then take care of the current bag
                for a in t.vertices:
                    node_type, inputs = nodes[a]
                    if t.idx == last[a]:
                        if a in unfinished[t]:
                            if len(unfinished[t][a]) == 1:
                                inputs.add(unfinished[t][a].pop())
                            else:
                                new_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ new_lit ] + [ -v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ -new_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ new_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in new_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ new_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in unfinished[t][a]:
                                        for vp in unfinished[t][a]:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])
                                inputs.add(new_lit)
                            del unfinished[t][a]
                        if node_type == AND:
                            bigAnd = [ a ] + [ -v for v in inputs ]
                            self._cnf.clauses.append(bigAnd)
                            for v in inputs:
                                self._cnf.clauses.append([ -a, v ])
                        elif node_type == OR:
                            bigOr = [ -a ] + [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            for v in inputs:
                                self._cnf.clauses.append([ a, -v ])
                        elif node_type == CON:
                            bigOr = [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            self._cnf.clauses.append([-a])
                        elif node_type == GUESS:
                            # make sure that at least one of the unfinished atoms is true
                            bigOr = [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            # make sure that not more than one of the unfinished atoms is true
                            for v in inputs:
                                for vp in inputs:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])
                            self._cnf.clauses.append([-a])
                        inputs.clear()
                    elif any([ t.idx == last[abs(b)] for b in inputs ]):
                        todo_new = set([ b for b in inputs if abs(b) in t.vertices ])
                        inputs.difference_update(todo_new)
                        if a not in unfinished[t]:
                            unfinished[t][a] = todo_new
                        else:
                            if len(unfinished[t][a]) == 1:
                                first_lit = unfinished[t][a].pop()
                            else:
                                first_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ -first_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ first_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in first_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ first_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in unfinished[t][a]:
                                        for vp in unfinished[t][a]:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])

                            if len(todo_new) == 1:
                                second_lit = todo_new.pop()
                            else:
                                second_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ -second_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ second_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in second_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ second_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in todo_new:
                                        for vp in todo_new:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])
                            unfinished[t][a] = set([first_lit, second_lit])

        if not latest:
            # finalize the nodes that are left in the root
            root = td.get_root()
            for a in unfinished[root]:
                node_type = nodes[a][0]
                if node_type == AND:
                    bigAnd = [ a ] + [ -v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigAnd)
                    for v in unfinished[root][a]:
                        self._cnf.clauses.append([ -a, v ])
                elif node_type == OR:
                    bigOr = [ -a ] + [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    for v in unfinished[root][a]:
                        self._cnf.clauses.append([ a, -v ])
                elif node_type == CON:
                    bigOr = [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    self._cnf.clauses.append([-a])
                elif node_type == GUESS:
                    # make sure that at least one of the unfinished atoms is true
                    bigOr = [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    # make sure that not more than one of the unfinished atoms is true
                    for v in unfinished[root][a]:
                        for vp in unfinished[root][a]:
                            if v &lt; vp:
                                self._cnf.clauses.append([-v, -vp])
                    self._cnf.clauses.append([-a])

        self._finalize_cnf()

    def choose_clark_completion(self):
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Chooses which of the clark completions to use based on an
        approximate check for the expected treewidth of the resulting CNF.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None
        &#34;&#34;&#34;
        # approximate final width when using both/adaptive strategy
        OR = 0
        AND = 1
        CON = 2
        GUESS = 3
        INPUT = 4
        # approximate final width when using none strategy
        nodes = { a : (OR, set()) for a in self._deriv }

        cur_max = self._max
        for a in self._exactlyOneOf:
            cur_max += 1
            nodes[cur_max] = (GUESS, set(abs(v) for v in a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        for r in self._program:
            cur_max += 1
            nodes[cur_max] = (AND, set(abs(v) for v in r.body))
            if len(r.head) != 0:
                nodes[abs(r.head[0])][1].add(cur_max)

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_both = 0
        for t in td.bag_iter():
            for tp in t.children:
                tp.parent = t

        for t in td.bag_iter():
            cur_cost = len(t.vertices)
            if t != td.get_root():
                kept = t.vertices.intersection(t.parent.vertices)
            else:
                kept = set()
            occ_counter = { a : 0 for a in t.vertices }
            for a in kept: 
                occ_counter[a] += 1
            for tp in t.children:
                for a in tp.vertices.intersection(t.vertices):
                    occ_counter[a] += 1
            for a, c in occ_counter.items():
                if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT:
                    cur_cost += 1
            if cur_cost &gt; cost_both:
                cost_both = cur_cost

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_none = td.width

        # approximate final width when using or strategy
        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            if inputs[0] == AND or inputs[0] == GUESS:
                graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            if inputs[0] != AND and inputs[0] != GUESS:
                graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_or = 0
        for t in td.bag_iter():
            for tp in t.children:
                tp.parent = t

        for t in td.bag_iter():
            cur_cost = len(t.vertices)
            if t != td.get_root():
                kept = t.vertices.intersection(t.parent.vertices)
            else:
                kept = set()
            occ_counter = { a : 0 for a in t.vertices }
            for a in kept: 
                occ_counter[a] += 1
            for tp in t.children:
                for a in tp.vertices.intersection(t.vertices):
                    occ_counter[a] += 1
            for a, c in occ_counter.items():
                if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT and nodes[a - cur_max][0] != AND and nodes[a - cur_max][0] != GUESS:
                    cur_cost += 1
            if cur_cost &gt; cost_or:
                cost_or = cur_cost

        logger.debug(f&#34;Approximate expected treewidth using strategy none: {cost_none}&#34;)
        logger.debug(f&#34;Approximate expected treewidth using strategy or: {cost_or}&#34;)
        logger.debug(f&#34;Approximate expected treewidth using strategy both/adaptive: {cost_both}&#34;)
        logger.info(&#34;------------------------------------------------------------&#34;)

        if cost_none &lt;= min(cost_both, cost_or) + 1:
            logger.info(f&#34;Choosing Unguided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.clark_completion()
        elif cost_or &lt;= cost_both + 1:
            logger.info(f&#34;Choosing OR-guided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.td_guided_clark_completion()
        else:
            logger.info(f&#34;Choosing completely guided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.td_guided_both_clark_completion(adaptive=True, latest = True)
    
    def build_bdds(self):
        from dd.cudd import BDD
        bdd = BDD()
        bdd.declare(*[ self._internal_name(v) for v in self._guess ])
        # set up the and/or graph
        graph = nx.DiGraph()
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(r, atom)
                for atom in r.body:
                    graph.add_edge(abs(atom), r)
        vertex_to_bdd = { v : bdd.var(self._internal_name(v)) for v in self._guess }
        ts = nx.topological_sort(graph)
        for cur in ts:
            if isinstance(cur, Rule):
                new_bdd = vertex_to_bdd[cur.body[0]]
                for b in cur.body[1:]:
                    new_bdd = new_bdd &amp; vertex_to_bdd[b]
                vertex_to_bdd[cur] = new_bdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_bdd = vertex_to_bdd[ins[0][0]]
                for r in ins[1:]:
                    new_bdd = new_bdd | vertex_to_bdd[r[0]]
                vertex_to_bdd[cur] = new_bdd
        return vertex_to_bdd

    def build_sdds(self):
        from aspmc.compile.vtree import TD_to_vtree
        from pysdd.sdd import Vtree, SddManager
        import tempfile
        # first generate a vtree for the program that is probably good
        OR = 0
        AND = 1
        GUESS = 3
        INPUT = 4
        # approximate final width when using none strategy
        nodes = { a : (OR, set()) for a in self._deriv }

        cur_max = self._max
        for a in self._exactlyOneOf:
            cur_max += 1
            nodes[cur_max] = (GUESS, set(abs(v) for v in a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        for r in self._program:
            cur_max += 1
            nodes[cur_max] = (AND, set(abs(v) for v in r.body))
            if len(r.head) != 0:
                nodes[abs(r.head[0])][1].add(cur_max)

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])))
        td.remove(set(range(1, cur_max + 1)).difference(self._guess))
        td.get_root().vertices.update(self._guess)
        my_vtree = TD_to_vtree(td)
        guesses = list(self._guess)
        rev_mapping = { guesses[i] : i + 1 for i in range(len(self._guess)) }
        for node in my_vtree:
            if node.val != None:
                assert(node.val in self._guess)
                node.val = rev_mapping[node.val]

        (_, vtree_tmp) = tempfile.mkstemp()
        my_vtree.write(vtree_tmp)
        vtree = Vtree(filename=vtree_tmp)
        sdd = SddManager.from_vtree(vtree)
        vars = list(sdd.vars)
        os.remove(vtree_tmp)
        vertex_to_sdd = { v : vars[i] for i,v in enumerate(guesses) }

        # set up the and/or graph
        graph = nx.DiGraph()
        for r in self._program:
            for atom in r.head:
                graph.add_edge(r, atom)
            for atom in r.body:
                graph.add_edge(abs(atom), r)

        # build the relevant sdds by traversing the graph in topological order
        ts = nx.topological_sort(graph)
        for cur in ts:
            if isinstance(cur, Rule):
                new_sdd = sdd.true()
                for b in cur.body:
                    if b &lt; 0:
                        vertex_to_sdd[b] = ~vertex_to_sdd[-b]
                    new_sdd = new_sdd &amp; vertex_to_sdd[b]
                vertex_to_sdd[cur] = new_sdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_sdd = sdd.false()
                for r in ins:
                    new_sdd = new_sdd | vertex_to_sdd[r[0]]
                vertex_to_sdd[cur] = new_sdd

        return vertex_to_sdd

    def to_aig(self, path):
        varMap = { name : var for var, name in self._nameMap.items() }
        inputs = &#34;\n&#34;.join( str(2*(i+1)) for i,v in enumerate(self._guess) )
        nr_ands = 0
        cur_idx = len(self._guess)
        and_aig = &#34;&#34;
        graph = nx.DiGraph()
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(r, atom)
                for atom in r.body:
                    graph.add_edge(abs(atom), r)
        ts = nx.topological_sort(graph)
        vertex_to_var = { v : 2*(i+1) for i,v in enumerate(self._guess) }
        for cur in ts:
            if isinstance(cur, Rule):
                if cur.body[0] &lt; 0:
                    vertex_to_var[cur.body[0]] = vertex_to_var[-cur.body[0]] ^ 1
                new_bdd = vertex_to_var[cur.body[0]]
                for b in cur.body[1:]:
                    if b &lt; 0:
                        vertex_to_var[b] = vertex_to_var[-b] ^ 1
                    nr_ands += 1
                    cur_idx += 1
                    and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[b]}\n&#34;
                    new_bdd = 2*cur_idx
                vertex_to_var[cur] = new_bdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_bdd = vertex_to_var[ins[0][0]] ^ 1
                for r in ins[1:]:
                    nr_ands += 1
                    cur_idx += 1
                    and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[r[0]] ^ 1}\n&#34;
                    new_bdd = 2*cur_idx
                vertex_to_var[cur] = new_bdd ^ 1
        outputs = &#34;\n&#34;.join( str(vertex_to_var[varMap[name]]) for name in self.get_queries() )
        with open(path, &#34;w&#34;) as out_file:
            out_file.write(f&#34;aag {cur_idx} {len(self._guess)} 0 {len(self.get_queries())} {nr_ands}\n&#34;)
            out_file.write(f&#34;{inputs}\n&#34;)
            out_file.write(f&#34;{outputs}\n&#34;)
            out_file.write(f&#34;{and_aig}&#34;)

    def _finalize_cnf(self):
        for l in self._copies.values():
            self._cnf.auxilliary.update(l)
        self._cnf.auxilliary.update(self._auxilliary)

    def encoding_stats(self):
        &#34;&#34;&#34;Print the stats of a tree decomposition of the cnf. 

        Returns:
            None        
        &#34;&#34;&#34;
        primal = Hypergraph()
        primal.add_nodes_from(range(1, self._max + 1))
        primal.add_edges_from([ set([ abs(x) for x in c ]) for c in self._cnf.clauses ])
        td = treedecomposition.from_hypergraph(primal)
        logger.info(f&#34;Tree Decomposition #bags: {td.bags} CNF treewidth: {td.width} #vertices: {td.vertices}&#34;)      

    def get_cnf(self):
        &#34;&#34;&#34;Used to get the extended cnf corresponding to the program. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        &#34;&#34;&#34;
        return self._cnf

    def write_dimacs(self, stream, **kwargs):
        &#34;&#34;&#34;Write the extended cnf corresponding to the program to a stream. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.

        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        &#34;&#34;&#34;
        # FIXME: this does not work anymore since auxilliary cnf vars do not have a name
        # if &#34;debug&#34; in kwargs:
        #     stream.write(f&#34;p cnf {self._cnf.nr_vars} {len(self._cnf.clauses)}\n&#34;.encode())
        #     for c in self._cnf.clauses:
        #         stream.write((&#34; &#34;.join([(&#34;(not &#34; if v &lt; 0 else &#34;(&#34;) + self._external_name(abs(v)) + &#34;)&#34; for v in c]) + &#34; 0\n&#34; ).encode())
        # else:
        self._cnf.to_stream(stream)


    def _prog_string(self, program):
        &#34;&#34;&#34;Get a string representation of a part of the program. 

        Should be overwritten by subclasses.

        Args:
            program (:obj:`list`): List of rules that should be printed.

        Returns:
            :obj:`string`: A string representation of the rules in `program`.        
        &#34;&#34;&#34;
        result = &#34;&#34;
        for r in self._exactlyOneOf:
            result += f&#34;1{{{&#39;;&#39;.join([ self._external_name(v) for v in r ])}}}1.\n&#34;
        for g in self._guess:
            result += f&#34;{{{self._external_name(g)}}}.\n&#34;
        for r in program:
            result += &#34;;&#34;.join([ self._external_name(v) for v in r.head ])
            if len(r.body) &gt; 0:
                result += &#34;:-&#34;
                result += &#34;,&#34;.join([(&#34;not &#34; if v &lt; 0 else &#34;&#34;) + self._external_name(abs(v)) for v in r.body])
            result += &#34;.\n&#34;
        return result

    def write_prog(self, stream, spanning = False):
        &#34;&#34;&#34;Write the (spanning) program to a stream.

        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.
            spanning (:obj:`bool`, optional): Whether the to write (case `False`) the actual program,
                possibly with weights and utilities and such or (case `True`) only the spanning program. 
                The spanning program corresponds to the underlying logical theory.
                Defaults to `False`.

        Returns:
            None     
        &#34;&#34;&#34;
        if spanning:
            stream.write(Program._prog_string(self, self._program).encode())
        else:
            stream.write(self._prog_string(self._program).encode())

    def get_weights(self):
        &#34;&#34;&#34;Get the weights of all the literals. 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of `weights` as numpy arrays.      
                The weight of literal `v` is in `weights[2*(v-1)]`, the one for `-v` is in `weights[2*(v-1)+1]`
        &#34;&#34;&#34;
        return [ np.array([1.0]) for _ in range(self._max*2) ]

    def get_queries(self):
        &#34;&#34;&#34;Get the queries (names not literals). 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of queries. 
                The empty list corresponds to asking for the overall weight of the program.
        &#34;&#34;&#34;
        return []</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="aspmc.programs.program.Program"><code class="flex name class">
<span>class <span class="ident">Program</span></span>
<span>(</span><span>clingo_control=&lt;aspmc.parsing.clingoparser.clingoext.Control object&gt;, program_str='', program_files=[], smodels=False)</span>
</code></dt>
<dd>
<div class="desc"><p>A base class for programs. No weights, no queries this is only for getting a cnf representation of the program.</p>
<p>Allowed features are: </p>
<ul>
<li>facts</li>
<li>normal rules</li>
<li>unconditional choice constraints</li>
<li>constraints</li>
</ul>
<p>The cnf is generated by first doing Tp-Unfolding and then applying a Clark completion to the resulting tight program. </p>
<h2 id="args">Args</h2>
<p>program_str (:obj:<code>string</code>): A string containing a part of the program in ASP syntax.
May be the empty string.
program_files (:obj:<code>list</code>): A list of string that are paths to files which contain programs in ASP syntax
that should be included. May be an empty list.
clingo_control (:obj:<code>Control</code>): A clingo control object that contains parts of the program.
Must already be ground if no non-empty <code>program_str</code> or <code>program_files</code> are given.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Program(object):
    &#34;&#34;&#34;A base class for programs. No weights, no queries this is only for getting a cnf representation of the program.

    Allowed features are: 

    * facts
    * normal rules
    * unconditional choice constraints
    * constraints

    The cnf is generated by first doing Tp-Unfolding and then applying a Clark completion to the resulting tight program. 

    Args:
        program_str (:obj:`string`): A string containing a part of the program in ASP syntax. 
            May be the empty string.
        program_files (:obj:`list`): A list of string that are paths to files which contain programs in ASP syntax 
            that should be included. May be an empty list.
        clingo_control (:obj:`Control`): A clingo control object that contains parts of the program. 
            Must already be ground if no non-empty `program_str` or `program_files` are given.
    &#34;&#34;&#34;
    def __init__(self, clingo_control = Control(), program_str = &#34;&#34;, program_files = [], smodels = False):
        # the variable counter
        self._max = 0
        self._nameMap = {}
        # store the clauses here
        self._cnf = CNF()
        # remember which variables are guesses, which are derived, and which are copies of derived atoms.
        self._guess = set()
        self._deriv = set()
        self._copies = {}
        # remember possible auxilliary variables that clingo introduced
        self._auxilliary = set()
        # the list containing all the rules (except guesses)
        self._program = []
        # remember which atoms have to satisfy an exactly one of constraint
        self._exactlyOneOf = set()
        # the tree decomposition of the program
        self._td = None
        if not smodels:
            if (len(program_str) &gt; 0 or len(program_files) &gt; 0):
                grounder.ground(clingo_control, program_str = program_str, program_files = program_files)
            self._normalize(clingo_control)
        else:
            if (len(program_str) &gt; 0 and len(program_files) &gt; 0) or len(program_files) &gt; 1:
                print(program_files, program_str)
                raise UnsupportedException(&#34;When instantiating a program from smodels format only one file or a program string may be given.&#34;)
            self._parse_smodels(program_str = program_str, program_files = program_files)

    def _parse_smodels(self, program_str = &#34;&#34;, program_files = []):
        if len(program_str) &gt; 0:
            lines = program_str.split(&#39;\n&#39;)
        else:
            with open(program_files[0], &#39;r&#39;) as in_file:
                lines = [ line[:-1] for line in in_file.readlines() ]

        for i in range(len(lines)):
            line = [ int(v) for v in lines[i].split(&#39; &#39;) ]
            if line[0] == 0:
                break
            elif line[0] == 1:
                head = [ line[1] ]
                nr_lit = line[2]
                nr_neg = line[3]
                body = line[4:4+nr_lit]
                self._max = max(head[0], self._max, max(body, default=0))
                for i in range(nr_neg):
                    body[i] *= -1
                self._program.append(Rule(head = head, body = body))
                self._deriv.add(head[0])
            elif line[0] == 3:
                if line[1] &gt; 1:
                    raise UnsupportedException(&#34;Currently no choice rules with more than one atom in the head are supported.&#34;)
                elif line[1] &gt; 0 and line[line[1] + 1] &gt; 0:
                    raise UnsupportedException(&#34;Currently conditional choice rules are not supported.&#34;)
                if line[1] == 1:
                    self._guess.add(line[2])
                    self._max = max(self._max(line[2]))
            else:
                raise UnsupportedException(f&#34;Unsupported rule type {line[0]}.&#34;)

        assert(len(self._deriv.intersection(self._guess)) == 0)
        ctr = i
        for i in range(ctr + 1, len(lines)):
            line = lines[i].split(&#39; &#39;)
            if line[0] == &#39;0&#39;:
                break
            self._nameMap[int(line[0])] = line[1]
            self._max = max(self._max, int(line[0]))
        ctr = i
        assert(lines[ctr + 1] == &#34;B+&#34;)
        for i in range(ctr + 2, len(lines)):
            if lines[i] == &#39;0&#39;:
                break
            self._program.append(Rule(head = [], body = [ -int(lines[i]) ]))
        ctr = i
        assert(lines[ctr + 1] == &#34;B-&#34;)
        for i in range(ctr + 2, len(lines)):
            if lines[i] == &#39;0&#39;:
                break
            self._program.append(Rule(head = [], body = [ int(lines[i]) ]))
        ctr = i
        if lines[ctr + 1] == &#34;E&#34;:
            for i in range(ctr + 2, len(lines)):
                if lines[i] == &#39;0&#39;:
                    break
                self._guess.add(int(lines[i]))
                
        self._deriv = set(range(1, self._max + 1))
        self._deriv.difference_update(self._guess)
        for v in self._deriv:
            if v not in self._nameMap:
                self._nameMap[v] = f&#34;projected_away({v})&#34;

    def _remove_tautologies(self, clingo_control):
        tmp = []
        for o in clingo_control.ground_program.objects:
            if isinstance(o, ClingoRule) and set(o.head).intersection(set(o.body)) == set():
                tmp.append(o)
        return tmp

    def _normalize(self, clingo_control):
        program = self._remove_tautologies(clingo_control)
        _atomToVertex = {} # the tree decomposition solver wants succinct numbering of vertices / no holes

        symbol_map = {}
        for sym in clingo_control.symbolic_atoms:
            symbol_map[sym.literal] = str(sym.symbol)
        for o in program:
            if isinstance(o, ClingoRule):
                if len(o.head) &gt; 1 and o.choice:
                    raise UnsupportedException(&#34;Currently no choice rules with more than one atom in the head are supported.&#34;)
                if len(o.body) &gt; 0 and o.choice:
                    raise UnsupportedException(&#34;Currently conditional choice rules are not supported.&#34;)
                o.atoms = set(o.head)
                o.atoms.update(tuple(map(abs, o.body)))
                # if we have the falsum rule we want to replace it with two rules
                if not o.atoms:
                    a = self._new_var(&#34;unsat&#34;)
                    orig_max = max( v for v in symbol_map.keys() ) + 1
                    _atomToVertex[orig_max] = a
                    o.atoms.add(orig_max)
                    o.head = [orig_max]
                    o.body = [-orig_max]
                    o.choice = False
                self._program.append(o)
                for a in o.atoms.difference(_atomToVertex):     # add mapping for atom not yet mapped
                    if a in symbol_map:
                        _atomToVertex[a] = self._new_var(symbol_map[a])
                    else:
                        aux_var = self._new_var(f&#34;projected_away({a})&#34;)
                        _atomToVertex[a] = aux_var
                        self._auxilliary.add(aux_var)

        trans_prog = set()
        self._deriv = set(range(1,self._max + 1))
        for r in self._program:
            if r.choice: 
                guess = [ _atomToVertex[r.head[0]] ]
                self._deriv.difference_update(guess)
                self._guess.update(guess)
            elif len(r.head) &gt; 1:
                guess = [ _atomToVertex[x] for x in r.head ]
                self._deriv.difference_update(guess)
                self._guess.update(guess)
                self._exactlyOneOf.add(frozenset(guess))
            else:
                head = list(map(lambda x: _atomToVertex[x], r.head))
                body = list(map(lambda x: _atomToVertex[abs(x)]*(1 if x &gt; 0 else -1), r.body))
                trans_prog.add(Rule(head,body))
        self._program = trans_prog

    def _new_var(self, name):
        self._max += 1
        self._nameMap[self._max] = name if name != &#34;&#34; else str(self._max)
        return self._max

    def _copy_var(self, var):
        if &#34;(&#34; in self._nameMap[var]:
            idx = self._nameMap[var].index(&#34;(&#34;)
            inputs = self._nameMap[var][idx:]
        else:
            inputs = &#34;&#34;
        if &#34;_copy_&#34; in self._nameMap[var]:
            idx = self._nameMap[var].index(&#34;_copy_&#34;)
            pred = self._nameMap[var][:idx]
        else:
            pred = self._nameMap[var]
            if &#34;(&#34; in pred:
                idx = pred.index(&#34;(&#34;)
                pred = pred[:idx]
            if pred+inputs not in self._copies:
                self._copies[pred+inputs] = [var]
        cnt = len(self._copies[pred+inputs])
        name = pred + &#34;_copy_&#34; + str(cnt) + inputs
        nv = self._new_var(name)
        self._copies[pred+inputs].append(nv)
        return nv

    def _internal_name(self, var):
        return self._nameMap[var]
    
    def _external_name(self, var):
        name = self._nameMap[var]
        # replace internal names with external names so we can parse programs that we print without errors
        for (internal, external) in conversions.items():
            name = name.replace(internal, external)
        return name

    def _computeComponents(self):
        self.dep = nx.DiGraph()
        self.dep.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            for a in r.head:
                for b in r.body:
                    if b &gt; 0:
                        self.dep.add_edge(b, a)
        comp = nx.algorithms.strongly_connected_components(self.dep)
        self._components = list(comp)
        self._condensation = nx.algorithms.condensation(self.dep, self._components)
        &#34;&#34;&#34;
        import matplotlib.pyplot as plt
        from networkx.drawing.nx_pydot import graphviz_layout
        labels = { node : str(node) for node in range(1, self._max + 1) }
        node_to_comp = {}
        for comp in self._components:
            for v in comp:
                node_to_comp[v] = comp
        red_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] == node_to_comp[u] ]
        edge_colours = [&#39;black&#39; if not edge in red_edges else &#39;red&#39; for edge in self.dep.edges()]
        black_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] != node_to_comp[u] ]
        pos = graphviz_layout(self.dep, prog=&#34;dot&#34;)
        nx.draw(self.dep, pos)
        nx.draw_networkx_labels(self.dep, pos, labels)
        nx.draw_networkx_edges(self.dep, pos, edgelist=red_edges, edge_color=&#39;r&#39;, arrows=True)
        nx.draw_networkx_edges(self.dep, pos, edgelist=black_edges, arrows=True)
        plt.axis(&#34;off&#34;)
        plt.show()
        &#34;&#34;&#34;

    def treeprocess(self):
        &#34;&#34;&#34;Applies tree processing to the program. 
        
        This means that if there is a part of the dependency graph that is a tree and
        only has one connection to the rest of the dependency graph, then it will be processed.

        Results in one copy for each atom in the tree.

        Returns:
            None        
        &#34;&#34;&#34;
        ins = {}
        outs = {}
        for a in self._deriv:
            ins[a] = set()
            outs[a] = set()

        for a in self._guess:
            ins[a] = set()
            outs[a] = set()

        for r in self._program:
            for a in r.head:
                ins[a].add(r)
            for b in r.body:
                if b &gt; 0:
                    outs[b].add(r)
        ts = nx.topological_sort(self._condensation)
        ancs = {}
        decs = {}
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            for v in comp:
                ancs[v] = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
                decs[v] = set([vp[1] for vp in self.dep.out_edges(nbunch=v) if vp[1] in comp])
        q = set([v for v in ancs.keys() if len(ancs[v]) == 1 and len(decs[v]) == 1 and list(ancs[v])[0] == list(decs[v])[0]])
        while not len(q) == 0:
            old_v = q.pop()
            if len(ancs[old_v]) == 0:
                continue
            new_v = self._copy_var(old_v)
            self._deriv.add(new_v)
            ins[new_v] = set()
            outs[new_v] = set()
            anc = ancs[old_v].pop()
            ancs[anc].remove(old_v)
            decs[anc].remove(old_v)
            if len(ancs[anc]) == 1 and len(decs[anc]) == 1 and list(ancs[anc])[0] == list(decs[anc])[0]:
                q.add(anc)

            # this contains all rules that do not use anc to derive v
            to_rem = ins[old_v].difference(outs[anc])
            # this contains all rules that use anc to derive v
            # we just keep them as they are
            ins[old_v] = ins[old_v].intersection(outs[anc])
            # any rule that does not use anc to derive v can now only derive new_v
            for r in to_rem:
                head = [b if b != old_v else new_v for b in r.head]
                new_r = Rule(head,r.body)
                ins[new_v].add(new_r)
                for b in r.body:
                    if b &gt; 0:
                        outs[b].remove(r)
                        outs[b].add(new_r)

            # this contains all rules that use v and derive anc
            to_rem = outs[old_v].intersection(ins[anc])
            # this contains all rules that use v and do not derive anc
            # we just keep them as they are
            outs[old_v] = outs[old_v].difference(ins[anc])
            # any rule that uses v to derive anc must use new_v
            for r in to_rem:
                body = [ (b if b != old_v else new_v) for b in r.body]
                new_r = Rule(r.head,body)
                for b in r.head:
                    ins[b].remove(r)
                    ins[b].add(new_r)
                for b in r.body:
                    if b &gt; 0:
                        if b != old_v:
                            outs[abs(b)].remove(r)
                            outs[abs(b)].add(new_r)
                        else:
                            outs[new_v].add(new_r)
            new_r = Rule([old_v], [new_v])
            ins[old_v].add(new_r)
            outs[new_v].add(new_r)
        # only keep the constraints
        self._program = [r for r in self._program if len(r.head) == 0]
        # add all the other rules
        for a in ins.keys():
            self._program.extend(ins[a])


    def _write_scc(self, comp):
        res = &#34;&#34;
        for v in comp:
            res += f&#34;p({v}).\n&#34;
            ancs = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            for vp in ancs:
                res += f&#34;edge({vp},{v}).\n&#34;
        return res

    def _compute_backdoor_clingo(self, idx, timeout = 30.0):
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        program_str = &#34;\n&#34;.join(f&#34;{{abs({v})}}.&#34; for v in comp) + &#34;\n&#34;
        program_str += &#34;:~ abs(X). [1,X]\n&#34;
        program_str += &#34;ok(X) :- abs(X).\n&#34;
        for v in comp:
            ancs = list(set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp] + [vp[0] for vp in self.dep.out_edges(nbunch=v) if vp[0] in comp]))
            for i in range(len(ancs)):
                program_str += f&#34;ok({v}) :- {&#39;,&#39;.join(f&#39;ok({vp})&#39; for vp in ancs[:i] + ancs[i+1:])}.\n&#34;
        program_str += &#34;\n&#34;.join(f&#34;:- not ok({v}).&#34; for v in comp) + &#34;\n&#34;
        program_str += &#34;#show abs/1.&#34;
        c = backdoor.ClingoControl(program_str)
        res = c.get_backdoor(None, timeout = timeout)[2][0]
        return res

    def _compute_backdoor_fvs(self, idx, timeout = 30.0, approximate = False):
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        edges = {}
        for v in comp:
            ancs = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            for vp in ancs:
                if vp &gt; v:
                    if v not in edges:
                        edges[v] = set()
                    edges[v].add(vp)
                else:
                    if vp not in edges:
                        edges[vp] = set()
                    edges[vp].add(v)
        graph = &#34;&#34;
        for v in edges.keys():
            for vp in edges[v]:
                graph += f&#34;{v} {vp}\n&#34;
        if not approximate:
            q = subprocess.Popen([os.path.join(src_path, &#34;fvs/src/build/FeedbackVertexSet&#34;)], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            output, err = q.communicate(input=graph.encode(), timeout = float(config.config[&#34;backdoort&#34;]))
        else:
            q = subprocess.Popen([os.path.join(src_path, &#34;fvs/src/build/FeedbackVertexSet&#34;), &#34;Appx&#34;], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            output, err = q.communicate(input=graph.encode())
        res = [ int(v) for v in output.decode().split()[1:] ]
        return res

    def _compute_backdoor(self, idx):
        start = time.time()
        comp = self._condensation.nodes[idx][&#34;members&#34;]
        try:
            if config.config[&#34;backdoors&#34;] == &#34;fvs&#34;:
                res = self._compute_backdoor_fvs(idx, timeout = float(config.config[&#34;backdoort&#34;]), approximate = False)
            elif config.config[&#34;backdoors&#34;] == &#34;clingo&#34;:
                res = self._compute_backdoor_clingo(idx, timeout = float(config.config[&#34;backdoort&#34;]))
        except (subprocess.TimeoutExpired,IndexError):
            logger.warning(f&#34;Optimal backdoor computation failed, switching to approximation.&#34;)
            res = self._compute_backdoor_fvs(idx, timeout = float(config.config[&#34;backdoort&#34;]), approximate = True)
        if False:
            import matplotlib.pyplot as plt
            from networkx.drawing.nx_pydot import graphviz_layout
            labels = { node : self._external_name(node) for node in comp }
            local_dep = self.dep.subgraph(comp)
            pos = graphviz_layout(local_dep, prog=&#34;neato&#34;)
            values = [ 1.0 if node in res else 0.0 for node in local_dep.nodes()]
            nx.draw(local_dep, pos, cmap=plt.get_cmap(&#39;viridis&#39;), node_color=values)
            nx.draw_networkx_labels(local_dep, pos, labels)
            plt.tight_layout()
            plt.axis(&#34;off&#34;)
            plt.show()
        logger.debug(&#34;backdoor comp: &#34; + str(len(comp)))
        logger.debug(&#34;backdoor res: &#34; + str(len(res)))
        logger.debug(f&#34;backdoor time: {time.time() - start}&#34;)
        return res

    def _backdoor_process(self, comp, backdoor):
        comp = set(comp)
        backdoor = set(backdoor)

        toRemove = set()
        ins = {}
        for a in comp:
            ins[a] = set()
        for r in self._program:
            for a in r.head:
                if a in comp:
                    ins[a].add(r)
                    toRemove.add(r)

        copies = {}
        for a in comp:
            copies[a] = {}
            copies[a][len(backdoor)] = a

        def getAtom(atom, i):
            # negated atoms are kept as they are
            if atom &lt; 0:
                return atom
            # atoms that are not from this component are input atoms and should stay the same
            if atom not in comp:
                return atom
            if i &lt; 0:
                print(&#34;this should not happen&#34;)
                exit(-1)
            if atom not in copies:
                print(&#34;this should not happen&#34;)
                exit(-1)
            if i not in copies[atom]:
                copies[atom][i] = self._copy_var(atom)
                self._deriv.add(copies[atom][i])
            return copies[atom][i]

        toAdd = set()
        for a in backdoor:
            for i in range(1,len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 1:
                        # in the first iteration we do not add rules that use atoms from the backdoor
                        add = True
                        for x in r.body:
                            if x &gt; 0 and x in backdoor:
                                add = False
                    else:
                        # in all but the first iteration we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x &gt; 0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i - 1) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i &gt; 1:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        for a in comp.difference(backdoor):
            for i in range(len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 0:
                        # in the first iteration we only add rules that only use atoms from outside 
                        add = True
                        for x in r.body:
                            if x &gt; 0 and x in backdoor:
                                add = False
                    else:
                        # in all other iterations we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x &gt;  0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i &gt; 0:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        self._program = [r for r in self._program if r not in toRemove]
        self._program += list(toAdd)
        
        
    def tpUnfold(self):
        &#34;&#34;&#34;Applies Tp-Unfolding to the program. 
        
        Applies a variant to be precise by first doing treeprocessing
        and then Tp-Unfolding as this can be a bit better.

        Returns:
            None        
        &#34;&#34;&#34;
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                backdoor = self._compute_backdoor(t)
                # if the backdoor needs more than half the atoms it is better if we use all the atoms as the backdoor
                # this is because treeprocessing has another factor*2 and backdoor*2 &gt; comp
                backdoor = comp if len(backdoor) &gt; len(comp)/2 else backdoor
                self._backdoor_process(comp, backdoor)
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                logger.error(&#34;Cycle breaking failed: the dependency graph still has a non-trivial SCC&#34;)
                exit(-1)

    def binary_cycle_breaking(self, local = False):
        if self._td is None and local:
            self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        self._computeComponents()
        # here we remember the new rules
        new_rules = []
        # maps a node t to a set of rules that need to be considered in t
        # it actually suffices if every rule is considered only once in the entire td..
        rules = {}
        # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
        lessThan = {}
        # remember which atoms we used for the bits 
        bits = {}
        if local:
            for t in self._td.bag_iter():
                bits[t] = {}
                tmp_vert = t.vertices.copy()
                while not len(tmp_vert) == 0:
                    cur = tmp_vert.pop()
                    if cur in self._condensation.graph[&#34;mapping&#34;]:
                        # otherwise cur does not occur positively
                        comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                        comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                        tmp_vert.difference_update(comp)
                        both = t.vertices.intersection(comp)
                        count = math.ceil(math.log(len(both),2))
                        for a in both:
                            bits[t][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},{t.idx},{i})&#34;) for i in range(count) ]
                            self._guess.update(bits[t][a])
        else:
            bits[None] = {}
            for comp in self._components:
                count = math.ceil(math.log(len(comp),2))
                for a in comp:
                    bits[None][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},none,{i})&#34;) for i in range(count)]
                    self._guess.update(bits[None][a])

        if local:
            # temporary copy of the program, will be empty after the first pass
            program = list(self._program)
            # first td pass: determine rules 
            for t in self._td.bag_iter():
                # take the rules we need and remove them
                rules[t] = [r for r in program if set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
                program = [r for r in program if not set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
        else: 
            rules[None] = list(self._program)

        # a subroutine to generate x &lt; x&#39;
        def generateLessThan(x, xp, local = False, node = None):
            assert(node is not None or not local)
            # setup and check if this has already been handled
            if not (x,xp,node) in lessThan:
                lessThan[(x,xp,node)] = self._new_var(f&#34;less_than({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)})&#34;)
                self._deriv.add(lessThan[(x,xp,node)])
            else:
                return lessThan[(x,xp,node)]

            # check if x and xp are in differens components
            xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
            xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
            if xs_comp != xps_comp:
                # determine which is in the higher component
                if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                    new_rules.append(Rule([lessThan[(x,xp,node)]],[]))
                elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                    new_rules.append(Rule([],[lessThan[(x,xp,node)]]))
                else: # there is no connection between these at all. should not occur.
                    logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                    exit(1)
                return lessThan[(x,xp,node)]

            # x and xp are in the same component 
            # obtain the bits and their number
            count = len(bits[node][x])
            x_bits = bits[node][x]
            xp_bits = bits[node][xp]

            # remember all the disjuncts here
            head = [ lessThan[(x,xp,node)] ]
            for i in range(count):
                body = [ xp_bits[i], -x_bits[i] ]
                for j in range(i + 1, count):
                    andVar = self._new_var(f&#34;less_than_bin({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)},{i},{j})&#34;)
                    self._deriv.add(andVar)
                    body.append(-andVar)
                    new_rules.append(Rule([andVar], [-xp_bits[j], x_bits[j]]))
                new_rules.append(Rule(head, body))
            return lessThan[(x,xp,node)]

        if local:
            # second td pass: use rules to generate the reduction
            for t in self._td.bag_iter():
                # generate (2), i.e. the constraints that maintain the inequalities between nodes
                for tp in t.children:
                    relevant = tp.vertices.intersection(t.vertices)
                    rel_cp = relevant.copy()
                    while len(rel_cp) &gt; 0:
                        cur = rel_cp.pop()
                        comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                        comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                        both = relevant.intersection(comp)
                        for x in both:
                            if x == cur:
                                continue
                            t_atom = generateLessThan(x, cur, local = local, node = t)
                            tp_atom = generateLessThan(x, cur, local = local, node = tp)
                            new_rules.append(Rule([],[t_atom, -tp_atom]))
                            new_rules.append(Rule([],[-t_atom, tp_atom]))
                                
                
                # add the order constraints to the rules in the current node
                for r in rules[t]:
                    if len(r.head) &gt; 0:
                        to_add = []
                        head = r.head[0]
                        for a in r.body:
                            if a &gt; 0:
                                to_add.append(generateLessThan(a, head, local = local, node = t))
                        new_rules.append(Rule([], [-head] + r.body))
                        r.body += to_add
                    new_rules.append(r)
        else:
            # add the order constraints to the rules in the current node
            for r in rules[None]:
                if len(r.head) &gt; 0:
                    to_add = []
                    head = r.head[0]
                    for a in r.body:
                        if a &gt; 0:
                            to_add.append(generateLessThan(a, head, local = local, node = None))
                    new_rules.append(Rule([], [-head] + r.body))
                    r.body += to_add
                new_rules.append(r)
        self._program = new_rules

    
     

    def less_than_cycle_breaking(self, opt = True):
        self._computeComponents()
        # here we remember the new rules
        new_rules = []
        # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
        lessThan = {}

        # a subroutine to generate x &lt; x&#39;
        def getLessThan(x, xp):
            negated = x &gt; xp
            if negated:
                x,xp = xp,x
            # setup and check if this has already been handled
            if not (x,xp) in lessThan:
                lessThan[(x,xp)] = self._new_var(f&#34;less_than({x},{xp})&#34;)
                # add the atoms as guesses
                self._guess.add(lessThan[(x,xp)])
            else:
                return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

            # check if x and xp are in differens components
            xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
            xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
            if xs_comp != xps_comp:
                # determine which is in the higher component
                if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                    new_rules.append(Rule([], [-lessThan[(x,xp)]]))
                elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                    new_rules.append(Rule([], [lessThan[(x,xp)]]))
                else: # there is no connection between these at all. should not occur.
                    logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                    exit(1)

            return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t][&#34;members&#34;]
            if len(comp) &gt; 1:
                # antisymmetry and connexity are true automatically
                if opt:
                    x_values = self._compute_backdoor(t)
                else:
                    x_values = comp
                # transitivity
                for x in x_values:
                    for y in comp:
                        if x == y:
                            continue
                        if opt:
                            z_values = self.dep.successors(y)
                        else:
                            z_values = comp
                        for z in z_values:
                            if y != z and x != z:
                                new_rules.append(Rule([], [getLessThan(x,y), getLessThan(y,z), -getLessThan(x,z)]))
                        
        
        # add lessThan atoms to break the cycles reduction
        for r in self._program:
            if len(r.head) &gt; 0:
                to_add = []
                head = r.head[0]
                for a in r.body:
                    if a &gt; 0:
                        to_add.append(getLessThan(a, head))
                new_rules.append(Rule([], [-head] + r.body))
                r.body += to_add
            new_rules.append(r)
        self._program = new_rules



    def _decomposeGraph(self, solver = &#34;flow-cutter&#34;, timeout = &#34;-1&#34;):            
        self._graph = Hypergraph()
        self._graph.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            atoms = set(r.head)
            atoms.update(tuple(map(abs, r.body)))
            self._graph.add_edge(atoms)
        self._td = treedecomposition.from_hypergraph(self._graph, solver = solver, timeout = timeout)

    def clark_completion(self):
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Does not use tree decomposition guidance to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars

        perAtom = {}
        for a in self._deriv:
            perAtom[a] = []

        for r in self._program:
            for a in r.head:
                perAtom[a].append(r)

        for head in self._deriv:
            ors = []
            for r in perAtom[head]:
                ors.append(aux_var())
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ors[-1]] + ands)
                for at in ands:
                    self._cnf.clauses.append([-ors[-1], -at])
            self._cnf.clauses.append([-head] + [o for o in ors])
            for o in ors:
                self._cnf.clauses.append([head, -o])

        # handle the constraints
        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])

        # handle the guesses
        for r in self._exactlyOneOf:
            # at least one
            self._cnf.clauses.append(list(r))
            # at most one
            for v in r:
                for vp in r:
                    if v &lt; vp:
                        self._cnf.clauses.append([-v, -vp])
                            
        self._finalize_cnf()

    def td_guided_clark_completion(self):        
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on the &#34;ors&#34; to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars
        
        self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        logger.info(f&#34;Tree Decomposition #bags: {self._td.bags} unfolded treewidth: {self._td.width} #vertices: {self._td.vertices}&#34;)
        # at which td node to handle each rule
        rules = {}
        # at which td node each variable occurs last
        last = {}
        idx = 0
        td_idx = list(self._td)
        for t in self._td.bag_iter():
            for a in t.vertices:
                last[a] = idx
            t.idx = idx
            idx += 1
            rules[t] = []

        for r in self._program:
            for a in r.head:
                r.proven = aux_var()
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ r.proven ] + ands)
                for at in ands:
                    self._cnf.clauses.append([ -r.proven, -at ])
            idx = min([ last[abs(b)] for b in r.body + r.head ])
            rules[self._td.get_bag(td_idx[idx])].append(r)

        # how many rules have we used and what is the last used variable
        unfinished = {}
        for t in self._td.bag_iter():
            unfinished[t] = {}
            t.vertices = set(t.vertices)
            to_handle = {}
            for a in t.vertices:
                to_handle[a] = []
            for tp in t.children:
                removed = tp.vertices.difference(t.vertices)
                for a in removed:
                    if a in self._deriv:
                        if a in unfinished[tp]:
                            final = unfinished[tp].pop(a)
                            self._cnf.clauses.append([-a, final])
                            self._cnf.clauses.append([a, -final])
                        else: 
                            self._cnf.clauses.append([-a])
                rest = tp.vertices.intersection(t.vertices)
                for a in rest:
                    if a in unfinished[tp]:
                        to_handle[a].append(unfinished[tp][a])

            # take the rules we need
            for r in rules[t]:
                for a in r.head:
                    to_handle[a].append(r.proven)

            # handle all the rules we have gathered
            for a in t.vertices:
                if len(to_handle[a]) &gt; 1:
                    new_last = aux_var()
                    self._cnf.clauses.append([-new_last] + to_handle[a])
                    for at in to_handle[a]:
                        self._cnf.clauses.append([new_last, -at])
                    unfinished[t][a] = new_last
                elif len(to_handle[a]) == 1:
                    unfinished[t][a] = to_handle[a][0]

        for a in self._td.get_root().vertices:
            if a in self._deriv:
                if a in unfinished[self._td.get_root()]:
                    final = unfinished[self._td.get_root()].pop(a)
                    self._cnf.clauses.append([-a, final])
                    self._cnf.clauses.append([a, -final])
                else: 
                    self._cnf.clauses.append([-a])

        # handle the constraints
        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])

       # handle the guesses
        for r in self._exactlyOneOf:
            # at least one
            self._cnf.clauses.append(list(r))
            # at most one
            for v in r:
                for vp in r:
                    if v &lt; vp:
                        self._cnf.clauses.append([-v, -vp])

        self._finalize_cnf()


    def td_guided_both_clark_completion(self, adaptive = False, latest = True): 
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on both the &#34;ands&#34; and the &#34;ors&#34;
        to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        &#34;&#34;&#34;
        self._cnf = CNF()
        self._cnf.nr_vars = self._max
        # local method to get a new auxilliary variable
        # so that the atom counter of the program does not change
        def aux_var():
            self._cnf.nr_vars += 1
            self._cnf.auxilliary.add(self._cnf.nr_vars)
            return self._cnf.nr_vars

        # remember whats an and, whats an or and whats a constraint
        # also include the guesses, which guess exactly one of their inputs to be true
        OR = 0
        AND = 1
        CON = 2
        GUESS = 3
        INPUT = 4
        nodes = { a : (OR, set()) for a in self._deriv }

        exactly_one_to_var = {}
        for a in self._exactlyOneOf:
            exactly_one_to_var[a] = aux_var()
            nodes[exactly_one_to_var[a]] = (GUESS, set(a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        if not latest:
            seen = set()
            facts = set([ r.head[0] for r in self._program if len(r.body) == 0 ])
            for f in facts:
                self._cnf.clauses.append([f])
            seen.update(facts)
        
        if not latest:
            remaining = [ r for r in self._program if len(r.head) == 0 or r.head[0] not in facts ]
        else:
            remaining = self._program
        for r in remaining:
            r.proven = aux_var()
            if len(r.head) != 0:
                nodes[r.proven] = (AND, set(r.body))
                nodes[abs(r.head[0])][1].add(r.proven)
                if not latest:
                    seen.add(r.head[0])
            else:
                nodes[r.proven] = (CON, set([ -atom for atom in r.body ]))

        if not latest:
            # handle the atoms that do not occur in the head of any rule
            falses = [ a for a in self._deriv if a not in seen and nodes[a][0] == OR and len(nodes[a][1]) == 0 ]
            for f in falses:
                self._cnf.clauses.append([-f])

        # set up the and/or graph
        graph = nx.Graph()
        graph.add_nodes_from(range(1, self._cnf.nr_vars + 1))
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(atom, r.proven)
                    if adaptive:
                        graph.add_edge(atom + self._cnf.nr_vars, r.proven)
                for atom in r.body:
                    graph.add_edge(r.proven, abs(atom))
                    if adaptive:
                        graph.add_edge(r.proven + self._cnf.nr_vars, abs(atom))
        
        for a in self._exactlyOneOf:
            for atom in a:
                graph.add_edge(exactly_one_to_var[a], atom)
                if adaptive:
                    graph.add_edge(exactly_one_to_var[a] + self._cnf.nr_vars, atom)


        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
        if adaptive:
            td.remove(set(range(self._cnf.nr_vars + 1, 2*self._cnf.nr_vars + 1)))
            td.vertices = self._cnf.nr_vars 
        logger.info(f&#34;Tree Decomposition #bags: {td.bags} unfolded treewidth: {td.width} #vertices: {td.vertices}&#34;)

        
        if latest:
            # at which td node each variable occurs last
            last = {}
            idx = 0
            for t in td.bag_iter():
                for a in t.vertices:
                    last[a] = idx
                t.idx = idx
                idx += 1
        
        # remember per bag which nodes have which partial result
        unfinished = {}
        # handle the bags in dfs order
        for t in td.bag_iter():
            unfinished[t] = {}
            # first take care of what we got from the children
            for tp in t.children:
                for atom in unfinished[tp]:
                    if atom not in unfinished[t]:
                        unfinished[t][atom] = unfinished[tp][atom]
                    else:
                        if len(unfinished[tp][atom]) == 1:
                            first_lit = unfinished[tp][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            first_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigAnd)                  
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                            elif node_type == GUESS:
                                # remember in first_lit, whether one of the unfinished atoms is true
                                bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[tp][atom]:
                                    for vp in unfinished[tp][atom]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        if len(unfinished[t][atom]) == 1:
                            second_lit = unfinished[t][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            second_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ second_lit, -v ])
                            elif node_type == GUESS:
                                # remember in second_lit, whether one of the unfinished atoms is true
                                bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ second_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][atom]:
                                    for vp in unfinished[t][atom]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        unfinished[t][atom] = set([first_lit, second_lit])
                        
            if not latest:
                # then take care of the current bag
                for a in t.vertices:
                    node_type, inputs = nodes[a]
                    todo_new = set([ atom for atom in inputs if abs(atom) in t.vertices ])
                    if len(todo_new) == 0:
                        continue
                    inputs.difference_update(todo_new)
                    if a not in unfinished[t]:
                        unfinished[t][a] = todo_new
                    else:
                        if len(unfinished[t][a]) == 1:
                            first_lit = unfinished[t][a].pop()
                        else:
                            first_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                            elif node_type == GUESS:
                                # remember in first_lit, whether one of the unfinished atoms is true
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][a]:
                                    for vp in unfinished[t][a]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        if len(todo_new) == 1:
                            second_lit = todo_new.pop()
                        else:
                            second_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                                self._cnf.clauses.append(bigAnd)
                                for v in todo_new:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                            elif node_type == GUESS:
                                # remember in second_lit, whether one of the unfinished atoms is true
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in todo_new:
                                    for vp in todo_new:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        unfinished[t][a] = set([first_lit, second_lit])

                
                # check which nodes are completely done and finalize them
                new_unfinished = {}
                for a in unfinished[t]:
                    if a in t.vertices: # if the variable is still there, we keep it
                        new_unfinished[a] = unfinished[t][a]
                    else: # otherwise we finalize the node
                        node_type = nodes[a][0]
                        if node_type == AND:
                            bigAnd = [ a ] + [ -v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigAnd)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ -a, v ])
                        elif node_type == OR:
                            bigOr = [ -a ] + [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ a, -v ])
                        elif node_type == CON:
                            bigOr = [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            self._cnf.clauses.append([-a])
                        elif node_type == GUESS:
                            # make sure that at least one of the unfinished atoms is true
                            bigOr = [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            # make sure that not more than one of the unfinished atoms is true
                            for v in unfinished[t][a]:
                                for vp in unfinished[t][a]:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])
                            self._cnf.clauses.append([-a])

                unfinished[t] = new_unfinished
            else:
                # then take care of the current bag
                for a in t.vertices:
                    node_type, inputs = nodes[a]
                    if t.idx == last[a]:
                        if a in unfinished[t]:
                            if len(unfinished[t][a]) == 1:
                                inputs.add(unfinished[t][a].pop())
                            else:
                                new_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ new_lit ] + [ -v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ -new_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ new_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in new_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ new_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in unfinished[t][a]:
                                        for vp in unfinished[t][a]:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])
                                inputs.add(new_lit)
                            del unfinished[t][a]
                        if node_type == AND:
                            bigAnd = [ a ] + [ -v for v in inputs ]
                            self._cnf.clauses.append(bigAnd)
                            for v in inputs:
                                self._cnf.clauses.append([ -a, v ])
                        elif node_type == OR:
                            bigOr = [ -a ] + [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            for v in inputs:
                                self._cnf.clauses.append([ a, -v ])
                        elif node_type == CON:
                            bigOr = [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            self._cnf.clauses.append([-a])
                        elif node_type == GUESS:
                            # make sure that at least one of the unfinished atoms is true
                            bigOr = [ v for v in inputs ]
                            self._cnf.clauses.append(bigOr)
                            # make sure that not more than one of the unfinished atoms is true
                            for v in inputs:
                                for vp in inputs:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])
                            self._cnf.clauses.append([-a])
                        inputs.clear()
                    elif any([ t.idx == last[abs(b)] for b in inputs ]):
                        todo_new = set([ b for b in inputs if abs(b) in t.vertices ])
                        inputs.difference_update(todo_new)
                        if a not in unfinished[t]:
                            unfinished[t][a] = todo_new
                        else:
                            if len(unfinished[t][a]) == 1:
                                first_lit = unfinished[t][a].pop()
                            else:
                                first_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ -first_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ first_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in first_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in unfinished[t][a]:
                                        self._cnf.clauses.append([ first_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in unfinished[t][a]:
                                        for vp in unfinished[t][a]:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])

                            if len(todo_new) == 1:
                                second_lit = todo_new.pop()
                            else:
                                second_lit = aux_var()
                                if node_type == AND:
                                    bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                                    self._cnf.clauses.append(bigAnd)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ -second_lit, v ])
                                elif node_type == OR or node_type == CON:
                                    bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ second_lit, -v ])
                                elif node_type == GUESS:
                                    # remember in second_lit, whether one of the unfinished atoms is true
                                    bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                    self._cnf.clauses.append(bigOr)
                                    for v in todo_new:
                                        self._cnf.clauses.append([ second_lit, -v ])
                                    # make sure that not more than one of the unfinished atoms is true
                                    for v in todo_new:
                                        for vp in todo_new:
                                            if v &lt; vp:
                                                self._cnf.clauses.append([-v, -vp])
                            unfinished[t][a] = set([first_lit, second_lit])

        if not latest:
            # finalize the nodes that are left in the root
            root = td.get_root()
            for a in unfinished[root]:
                node_type = nodes[a][0]
                if node_type == AND:
                    bigAnd = [ a ] + [ -v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigAnd)
                    for v in unfinished[root][a]:
                        self._cnf.clauses.append([ -a, v ])
                elif node_type == OR:
                    bigOr = [ -a ] + [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    for v in unfinished[root][a]:
                        self._cnf.clauses.append([ a, -v ])
                elif node_type == CON:
                    bigOr = [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    self._cnf.clauses.append([-a])
                elif node_type == GUESS:
                    # make sure that at least one of the unfinished atoms is true
                    bigOr = [ v for v in unfinished[root][a] ]
                    self._cnf.clauses.append(bigOr)
                    # make sure that not more than one of the unfinished atoms is true
                    for v in unfinished[root][a]:
                        for vp in unfinished[root][a]:
                            if v &lt; vp:
                                self._cnf.clauses.append([-v, -vp])
                    self._cnf.clauses.append([-a])

        self._finalize_cnf()

    def choose_clark_completion(self):
        &#34;&#34;&#34;Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Chooses which of the clark completions to use based on an
        approximate check for the expected treewidth of the resulting CNF.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None
        &#34;&#34;&#34;
        # approximate final width when using both/adaptive strategy
        OR = 0
        AND = 1
        CON = 2
        GUESS = 3
        INPUT = 4
        # approximate final width when using none strategy
        nodes = { a : (OR, set()) for a in self._deriv }

        cur_max = self._max
        for a in self._exactlyOneOf:
            cur_max += 1
            nodes[cur_max] = (GUESS, set(abs(v) for v in a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        for r in self._program:
            cur_max += 1
            nodes[cur_max] = (AND, set(abs(v) for v in r.body))
            if len(r.head) != 0:
                nodes[abs(r.head[0])][1].add(cur_max)

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_both = 0
        for t in td.bag_iter():
            for tp in t.children:
                tp.parent = t

        for t in td.bag_iter():
            cur_cost = len(t.vertices)
            if t != td.get_root():
                kept = t.vertices.intersection(t.parent.vertices)
            else:
                kept = set()
            occ_counter = { a : 0 for a in t.vertices }
            for a in kept: 
                occ_counter[a] += 1
            for tp in t.children:
                for a in tp.vertices.intersection(t.vertices):
                    occ_counter[a] += 1
            for a, c in occ_counter.items():
                if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT:
                    cur_cost += 1
            if cur_cost &gt; cost_both:
                cost_both = cur_cost

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_none = td.width

        # approximate final width when using or strategy
        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            if inputs[0] == AND or inputs[0] == GUESS:
                graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            if inputs[0] != AND and inputs[0] != GUESS:
                graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
        cost_or = 0
        for t in td.bag_iter():
            for tp in t.children:
                tp.parent = t

        for t in td.bag_iter():
            cur_cost = len(t.vertices)
            if t != td.get_root():
                kept = t.vertices.intersection(t.parent.vertices)
            else:
                kept = set()
            occ_counter = { a : 0 for a in t.vertices }
            for a in kept: 
                occ_counter[a] += 1
            for tp in t.children:
                for a in tp.vertices.intersection(t.vertices):
                    occ_counter[a] += 1
            for a, c in occ_counter.items():
                if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT and nodes[a - cur_max][0] != AND and nodes[a - cur_max][0] != GUESS:
                    cur_cost += 1
            if cur_cost &gt; cost_or:
                cost_or = cur_cost

        logger.debug(f&#34;Approximate expected treewidth using strategy none: {cost_none}&#34;)
        logger.debug(f&#34;Approximate expected treewidth using strategy or: {cost_or}&#34;)
        logger.debug(f&#34;Approximate expected treewidth using strategy both/adaptive: {cost_both}&#34;)
        logger.info(&#34;------------------------------------------------------------&#34;)

        if cost_none &lt;= min(cost_both, cost_or) + 1:
            logger.info(f&#34;Choosing Unguided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.clark_completion()
        elif cost_or &lt;= cost_both + 1:
            logger.info(f&#34;Choosing OR-guided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.td_guided_clark_completion()
        else:
            logger.info(f&#34;Choosing completely guided Clark Completion&#34;)
            logger.info(&#34;------------------------------------------------------------&#34;)
            self.td_guided_both_clark_completion(adaptive=True, latest = True)
    
    def build_bdds(self):
        from dd.cudd import BDD
        bdd = BDD()
        bdd.declare(*[ self._internal_name(v) for v in self._guess ])
        # set up the and/or graph
        graph = nx.DiGraph()
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(r, atom)
                for atom in r.body:
                    graph.add_edge(abs(atom), r)
        vertex_to_bdd = { v : bdd.var(self._internal_name(v)) for v in self._guess }
        ts = nx.topological_sort(graph)
        for cur in ts:
            if isinstance(cur, Rule):
                new_bdd = vertex_to_bdd[cur.body[0]]
                for b in cur.body[1:]:
                    new_bdd = new_bdd &amp; vertex_to_bdd[b]
                vertex_to_bdd[cur] = new_bdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_bdd = vertex_to_bdd[ins[0][0]]
                for r in ins[1:]:
                    new_bdd = new_bdd | vertex_to_bdd[r[0]]
                vertex_to_bdd[cur] = new_bdd
        return vertex_to_bdd

    def build_sdds(self):
        from aspmc.compile.vtree import TD_to_vtree
        from pysdd.sdd import Vtree, SddManager
        import tempfile
        # first generate a vtree for the program that is probably good
        OR = 0
        AND = 1
        GUESS = 3
        INPUT = 4
        # approximate final width when using none strategy
        nodes = { a : (OR, set()) for a in self._deriv }

        cur_max = self._max
        for a in self._exactlyOneOf:
            cur_max += 1
            nodes[cur_max] = (GUESS, set(abs(v) for v in a))

        for atom in self._guess:
            nodes[atom] = (INPUT, set())

        for r in self._program:
            cur_max += 1
            nodes[cur_max] = (AND, set(abs(v) for v in r.body))
            if len(r.head) != 0:
                nodes[abs(r.head[0])][1].add(cur_max)

        # set up the and/or graph
        graph = nx.Graph()
        for a, inputs in nodes.items():
            graph.add_edges_from([ (a, v) for v in inputs[1] ])
            
        td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])))
        td.remove(set(range(1, cur_max + 1)).difference(self._guess))
        td.get_root().vertices.update(self._guess)
        my_vtree = TD_to_vtree(td)
        guesses = list(self._guess)
        rev_mapping = { guesses[i] : i + 1 for i in range(len(self._guess)) }
        for node in my_vtree:
            if node.val != None:
                assert(node.val in self._guess)
                node.val = rev_mapping[node.val]

        (_, vtree_tmp) = tempfile.mkstemp()
        my_vtree.write(vtree_tmp)
        vtree = Vtree(filename=vtree_tmp)
        sdd = SddManager.from_vtree(vtree)
        vars = list(sdd.vars)
        os.remove(vtree_tmp)
        vertex_to_sdd = { v : vars[i] for i,v in enumerate(guesses) }

        # set up the and/or graph
        graph = nx.DiGraph()
        for r in self._program:
            for atom in r.head:
                graph.add_edge(r, atom)
            for atom in r.body:
                graph.add_edge(abs(atom), r)

        # build the relevant sdds by traversing the graph in topological order
        ts = nx.topological_sort(graph)
        for cur in ts:
            if isinstance(cur, Rule):
                new_sdd = sdd.true()
                for b in cur.body:
                    if b &lt; 0:
                        vertex_to_sdd[b] = ~vertex_to_sdd[-b]
                    new_sdd = new_sdd &amp; vertex_to_sdd[b]
                vertex_to_sdd[cur] = new_sdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_sdd = sdd.false()
                for r in ins:
                    new_sdd = new_sdd | vertex_to_sdd[r[0]]
                vertex_to_sdd[cur] = new_sdd

        return vertex_to_sdd

    def to_aig(self, path):
        varMap = { name : var for var, name in self._nameMap.items() }
        inputs = &#34;\n&#34;.join( str(2*(i+1)) for i,v in enumerate(self._guess) )
        nr_ands = 0
        cur_idx = len(self._guess)
        and_aig = &#34;&#34;
        graph = nx.DiGraph()
        for r in self._program:
            if len(r.body) &gt; 0:
                for atom in r.head:
                    graph.add_edge(r, atom)
                for atom in r.body:
                    graph.add_edge(abs(atom), r)
        ts = nx.topological_sort(graph)
        vertex_to_var = { v : 2*(i+1) for i,v in enumerate(self._guess) }
        for cur in ts:
            if isinstance(cur, Rule):
                if cur.body[0] &lt; 0:
                    vertex_to_var[cur.body[0]] = vertex_to_var[-cur.body[0]] ^ 1
                new_bdd = vertex_to_var[cur.body[0]]
                for b in cur.body[1:]:
                    if b &lt; 0:
                        vertex_to_var[b] = vertex_to_var[-b] ^ 1
                    nr_ands += 1
                    cur_idx += 1
                    and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[b]}\n&#34;
                    new_bdd = 2*cur_idx
                vertex_to_var[cur] = new_bdd
            elif cur not in self._guess:
                ins = list(graph.in_edges(nbunch=cur))
                new_bdd = vertex_to_var[ins[0][0]] ^ 1
                for r in ins[1:]:
                    nr_ands += 1
                    cur_idx += 1
                    and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[r[0]] ^ 1}\n&#34;
                    new_bdd = 2*cur_idx
                vertex_to_var[cur] = new_bdd ^ 1
        outputs = &#34;\n&#34;.join( str(vertex_to_var[varMap[name]]) for name in self.get_queries() )
        with open(path, &#34;w&#34;) as out_file:
            out_file.write(f&#34;aag {cur_idx} {len(self._guess)} 0 {len(self.get_queries())} {nr_ands}\n&#34;)
            out_file.write(f&#34;{inputs}\n&#34;)
            out_file.write(f&#34;{outputs}\n&#34;)
            out_file.write(f&#34;{and_aig}&#34;)

    def _finalize_cnf(self):
        for l in self._copies.values():
            self._cnf.auxilliary.update(l)
        self._cnf.auxilliary.update(self._auxilliary)

    def encoding_stats(self):
        &#34;&#34;&#34;Print the stats of a tree decomposition of the cnf. 

        Returns:
            None        
        &#34;&#34;&#34;
        primal = Hypergraph()
        primal.add_nodes_from(range(1, self._max + 1))
        primal.add_edges_from([ set([ abs(x) for x in c ]) for c in self._cnf.clauses ])
        td = treedecomposition.from_hypergraph(primal)
        logger.info(f&#34;Tree Decomposition #bags: {td.bags} CNF treewidth: {td.width} #vertices: {td.vertices}&#34;)      

    def get_cnf(self):
        &#34;&#34;&#34;Used to get the extended cnf corresponding to the program. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        &#34;&#34;&#34;
        return self._cnf

    def write_dimacs(self, stream, **kwargs):
        &#34;&#34;&#34;Write the extended cnf corresponding to the program to a stream. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.

        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        &#34;&#34;&#34;
        # FIXME: this does not work anymore since auxilliary cnf vars do not have a name
        # if &#34;debug&#34; in kwargs:
        #     stream.write(f&#34;p cnf {self._cnf.nr_vars} {len(self._cnf.clauses)}\n&#34;.encode())
        #     for c in self._cnf.clauses:
        #         stream.write((&#34; &#34;.join([(&#34;(not &#34; if v &lt; 0 else &#34;(&#34;) + self._external_name(abs(v)) + &#34;)&#34; for v in c]) + &#34; 0\n&#34; ).encode())
        # else:
        self._cnf.to_stream(stream)


    def _prog_string(self, program):
        &#34;&#34;&#34;Get a string representation of a part of the program. 

        Should be overwritten by subclasses.

        Args:
            program (:obj:`list`): List of rules that should be printed.

        Returns:
            :obj:`string`: A string representation of the rules in `program`.        
        &#34;&#34;&#34;
        result = &#34;&#34;
        for r in self._exactlyOneOf:
            result += f&#34;1{{{&#39;;&#39;.join([ self._external_name(v) for v in r ])}}}1.\n&#34;
        for g in self._guess:
            result += f&#34;{{{self._external_name(g)}}}.\n&#34;
        for r in program:
            result += &#34;;&#34;.join([ self._external_name(v) for v in r.head ])
            if len(r.body) &gt; 0:
                result += &#34;:-&#34;
                result += &#34;,&#34;.join([(&#34;not &#34; if v &lt; 0 else &#34;&#34;) + self._external_name(abs(v)) for v in r.body])
            result += &#34;.\n&#34;
        return result

    def write_prog(self, stream, spanning = False):
        &#34;&#34;&#34;Write the (spanning) program to a stream.

        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.
            spanning (:obj:`bool`, optional): Whether the to write (case `False`) the actual program,
                possibly with weights and utilities and such or (case `True`) only the spanning program. 
                The spanning program corresponds to the underlying logical theory.
                Defaults to `False`.

        Returns:
            None     
        &#34;&#34;&#34;
        if spanning:
            stream.write(Program._prog_string(self, self._program).encode())
        else:
            stream.write(self._prog_string(self._program).encode())

    def get_weights(self):
        &#34;&#34;&#34;Get the weights of all the literals. 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of `weights` as numpy arrays.      
                The weight of literal `v` is in `weights[2*(v-1)]`, the one for `-v` is in `weights[2*(v-1)+1]`
        &#34;&#34;&#34;
        return [ np.array([1.0]) for _ in range(self._max*2) ]

    def get_queries(self):
        &#34;&#34;&#34;Get the queries (names not literals). 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of queries. 
                The empty list corresponds to asking for the overall weight of the program.
        &#34;&#34;&#34;
        return []</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="aspmc.programs.algebraicprogram.AlgebraicProgram" href="algebraicprogram.html#aspmc.programs.algebraicprogram.AlgebraicProgram">AlgebraicProgram</a></li>
<li><a title="aspmc.programs.nestedalgebraicprogram.NestedAlgebraicProgram" href="nestedalgebraicprogram.html#aspmc.programs.nestedalgebraicprogram.NestedAlgebraicProgram">NestedAlgebraicProgram</a></li>
<li><a title="aspmc.programs.optprogram.OptProgram" href="optprogram.html#aspmc.programs.optprogram.OptProgram">OptProgram</a></li>
<li><a title="aspmc.programs.problogprogram.ProblogProgram" href="problogprogram.html#aspmc.programs.problogprogram.ProblogProgram">ProblogProgram</a></li>
<li><a title="aspmc.programs.twoalgebraicprogram.TwoAlgebraicProgram" href="twoalgebraicprogram.html#aspmc.programs.twoalgebraicprogram.TwoAlgebraicProgram">TwoAlgebraicProgram</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="aspmc.programs.program.Program.binary_cycle_breaking"><code class="name flex">
<span>def <span class="ident">binary_cycle_breaking</span></span>(<span>self, local=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def binary_cycle_breaking(self, local = False):
    if self._td is None and local:
        self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
    self._computeComponents()
    # here we remember the new rules
    new_rules = []
    # maps a node t to a set of rules that need to be considered in t
    # it actually suffices if every rule is considered only once in the entire td..
    rules = {}
    # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
    lessThan = {}
    # remember which atoms we used for the bits 
    bits = {}
    if local:
        for t in self._td.bag_iter():
            bits[t] = {}
            tmp_vert = t.vertices.copy()
            while not len(tmp_vert) == 0:
                cur = tmp_vert.pop()
                if cur in self._condensation.graph[&#34;mapping&#34;]:
                    # otherwise cur does not occur positively
                    comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                    comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                    tmp_vert.difference_update(comp)
                    both = t.vertices.intersection(comp)
                    count = math.ceil(math.log(len(both),2))
                    for a in both:
                        bits[t][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},{t.idx},{i})&#34;) for i in range(count) ]
                        self._guess.update(bits[t][a])
    else:
        bits[None] = {}
        for comp in self._components:
            count = math.ceil(math.log(len(comp),2))
            for a in comp:
                bits[None][a] = [ self._new_var(f&#34;bin_counter({self._external_name(a)},none,{i})&#34;) for i in range(count)]
                self._guess.update(bits[None][a])

    if local:
        # temporary copy of the program, will be empty after the first pass
        program = list(self._program)
        # first td pass: determine rules 
        for t in self._td.bag_iter():
            # take the rules we need and remove them
            rules[t] = [r for r in program if set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
            program = [r for r in program if not set(r.head + [ abs(x) for x in r.body ]).issubset(t.vertices)]
    else: 
        rules[None] = list(self._program)

    # a subroutine to generate x &lt; x&#39;
    def generateLessThan(x, xp, local = False, node = None):
        assert(node is not None or not local)
        # setup and check if this has already been handled
        if not (x,xp,node) in lessThan:
            lessThan[(x,xp,node)] = self._new_var(f&#34;less_than({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)})&#34;)
            self._deriv.add(lessThan[(x,xp,node)])
        else:
            return lessThan[(x,xp,node)]

        # check if x and xp are in differens components
        xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
        xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
        if xs_comp != xps_comp:
            # determine which is in the higher component
            if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                new_rules.append(Rule([lessThan[(x,xp,node)]],[]))
            elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                new_rules.append(Rule([],[lessThan[(x,xp,node)]]))
            else: # there is no connection between these at all. should not occur.
                logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                exit(1)
            return lessThan[(x,xp,node)]

        # x and xp are in the same component 
        # obtain the bits and their number
        count = len(bits[node][x])
        x_bits = bits[node][x]
        xp_bits = bits[node][xp]

        # remember all the disjuncts here
        head = [ lessThan[(x,xp,node)] ]
        for i in range(count):
            body = [ xp_bits[i], -x_bits[i] ]
            for j in range(i + 1, count):
                andVar = self._new_var(f&#34;less_than_bin({self._external_name(x)},{node.idx if node is not None else &#39;none&#39;},{self._external_name(xp)},{i},{j})&#34;)
                self._deriv.add(andVar)
                body.append(-andVar)
                new_rules.append(Rule([andVar], [-xp_bits[j], x_bits[j]]))
            new_rules.append(Rule(head, body))
        return lessThan[(x,xp,node)]

    if local:
        # second td pass: use rules to generate the reduction
        for t in self._td.bag_iter():
            # generate (2), i.e. the constraints that maintain the inequalities between nodes
            for tp in t.children:
                relevant = tp.vertices.intersection(t.vertices)
                rel_cp = relevant.copy()
                while len(rel_cp) &gt; 0:
                    cur = rel_cp.pop()
                    comp_id = self._condensation.graph[&#34;mapping&#34;][cur]
                    comp = self._condensation.nodes[comp_id][&#34;members&#34;]
                    both = relevant.intersection(comp)
                    for x in both:
                        if x == cur:
                            continue
                        t_atom = generateLessThan(x, cur, local = local, node = t)
                        tp_atom = generateLessThan(x, cur, local = local, node = tp)
                        new_rules.append(Rule([],[t_atom, -tp_atom]))
                        new_rules.append(Rule([],[-t_atom, tp_atom]))
                            
            
            # add the order constraints to the rules in the current node
            for r in rules[t]:
                if len(r.head) &gt; 0:
                    to_add = []
                    head = r.head[0]
                    for a in r.body:
                        if a &gt; 0:
                            to_add.append(generateLessThan(a, head, local = local, node = t))
                    new_rules.append(Rule([], [-head] + r.body))
                    r.body += to_add
                new_rules.append(r)
    else:
        # add the order constraints to the rules in the current node
        for r in rules[None]:
            if len(r.head) &gt; 0:
                to_add = []
                head = r.head[0]
                for a in r.body:
                    if a &gt; 0:
                        to_add.append(generateLessThan(a, head, local = local, node = None))
                new_rules.append(Rule([], [-head] + r.body))
                r.body += to_add
            new_rules.append(r)
    self._program = new_rules</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.build_bdds"><code class="name flex">
<span>def <span class="ident">build_bdds</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_bdds(self):
    from dd.cudd import BDD
    bdd = BDD()
    bdd.declare(*[ self._internal_name(v) for v in self._guess ])
    # set up the and/or graph
    graph = nx.DiGraph()
    for r in self._program:
        if len(r.body) &gt; 0:
            for atom in r.head:
                graph.add_edge(r, atom)
            for atom in r.body:
                graph.add_edge(abs(atom), r)
    vertex_to_bdd = { v : bdd.var(self._internal_name(v)) for v in self._guess }
    ts = nx.topological_sort(graph)
    for cur in ts:
        if isinstance(cur, Rule):
            new_bdd = vertex_to_bdd[cur.body[0]]
            for b in cur.body[1:]:
                new_bdd = new_bdd &amp; vertex_to_bdd[b]
            vertex_to_bdd[cur] = new_bdd
        elif cur not in self._guess:
            ins = list(graph.in_edges(nbunch=cur))
            new_bdd = vertex_to_bdd[ins[0][0]]
            for r in ins[1:]:
                new_bdd = new_bdd | vertex_to_bdd[r[0]]
            vertex_to_bdd[cur] = new_bdd
    return vertex_to_bdd</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.build_sdds"><code class="name flex">
<span>def <span class="ident">build_sdds</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_sdds(self):
    from aspmc.compile.vtree import TD_to_vtree
    from pysdd.sdd import Vtree, SddManager
    import tempfile
    # first generate a vtree for the program that is probably good
    OR = 0
    AND = 1
    GUESS = 3
    INPUT = 4
    # approximate final width when using none strategy
    nodes = { a : (OR, set()) for a in self._deriv }

    cur_max = self._max
    for a in self._exactlyOneOf:
        cur_max += 1
        nodes[cur_max] = (GUESS, set(abs(v) for v in a))

    for atom in self._guess:
        nodes[atom] = (INPUT, set())

    for r in self._program:
        cur_max += 1
        nodes[cur_max] = (AND, set(abs(v) for v in r.body))
        if len(r.head) != 0:
            nodes[abs(r.head[0])][1].add(cur_max)

    # set up the and/or graph
    graph = nx.Graph()
    for a, inputs in nodes.items():
        graph.add_edges_from([ (a, v) for v in inputs[1] ])
        
    td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])))
    td.remove(set(range(1, cur_max + 1)).difference(self._guess))
    td.get_root().vertices.update(self._guess)
    my_vtree = TD_to_vtree(td)
    guesses = list(self._guess)
    rev_mapping = { guesses[i] : i + 1 for i in range(len(self._guess)) }
    for node in my_vtree:
        if node.val != None:
            assert(node.val in self._guess)
            node.val = rev_mapping[node.val]

    (_, vtree_tmp) = tempfile.mkstemp()
    my_vtree.write(vtree_tmp)
    vtree = Vtree(filename=vtree_tmp)
    sdd = SddManager.from_vtree(vtree)
    vars = list(sdd.vars)
    os.remove(vtree_tmp)
    vertex_to_sdd = { v : vars[i] for i,v in enumerate(guesses) }

    # set up the and/or graph
    graph = nx.DiGraph()
    for r in self._program:
        for atom in r.head:
            graph.add_edge(r, atom)
        for atom in r.body:
            graph.add_edge(abs(atom), r)

    # build the relevant sdds by traversing the graph in topological order
    ts = nx.topological_sort(graph)
    for cur in ts:
        if isinstance(cur, Rule):
            new_sdd = sdd.true()
            for b in cur.body:
                if b &lt; 0:
                    vertex_to_sdd[b] = ~vertex_to_sdd[-b]
                new_sdd = new_sdd &amp; vertex_to_sdd[b]
            vertex_to_sdd[cur] = new_sdd
        elif cur not in self._guess:
            ins = list(graph.in_edges(nbunch=cur))
            new_sdd = sdd.false()
            for r in ins:
                new_sdd = new_sdd | vertex_to_sdd[r[0]]
            vertex_to_sdd[cur] = new_sdd

    return vertex_to_sdd</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.choose_clark_completion"><code class="name flex">
<span>def <span class="ident">choose_clark_completion</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies the clark completion to the program. </p>
<p>Does not check whether the program is tight!
Chooses which of the clark completions to use based on an
approximate check for the expected treewidth of the resulting CNF.</p>
<p>Does not return anything only constructs the cnf.
The CNF can be obtained by using <code>get_cnf()</code>.</p>
<p>The solver to compute the tree decomposition and its timeout can be specified in
aspmc.config.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def choose_clark_completion(self):
    &#34;&#34;&#34;Applies the clark completion to the program. 

    Does not check whether the program is tight! 
    Chooses which of the clark completions to use based on an
    approximate check for the expected treewidth of the resulting CNF.
    
    Does not return anything only constructs the cnf.
    The CNF can be obtained by using `get_cnf()`.

    The solver to compute the tree decomposition and its timeout can be specified in 
    aspmc.config.

    Returns:
        None
    &#34;&#34;&#34;
    # approximate final width when using both/adaptive strategy
    OR = 0
    AND = 1
    CON = 2
    GUESS = 3
    INPUT = 4
    # approximate final width when using none strategy
    nodes = { a : (OR, set()) for a in self._deriv }

    cur_max = self._max
    for a in self._exactlyOneOf:
        cur_max += 1
        nodes[cur_max] = (GUESS, set(abs(v) for v in a))

    for atom in self._guess:
        nodes[atom] = (INPUT, set())

    for r in self._program:
        cur_max += 1
        nodes[cur_max] = (AND, set(abs(v) for v in r.body))
        if len(r.head) != 0:
            nodes[abs(r.head[0])][1].add(cur_max)

    # set up the and/or graph
    graph = nx.Graph()
    for a, inputs in nodes.items():
        graph.add_edges_from([ (a, v) for v in inputs[1] ])
        graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
        
    td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
    cost_both = 0
    for t in td.bag_iter():
        for tp in t.children:
            tp.parent = t

    for t in td.bag_iter():
        cur_cost = len(t.vertices)
        if t != td.get_root():
            kept = t.vertices.intersection(t.parent.vertices)
        else:
            kept = set()
        occ_counter = { a : 0 for a in t.vertices }
        for a in kept: 
            occ_counter[a] += 1
        for tp in t.children:
            for a in tp.vertices.intersection(t.vertices):
                occ_counter[a] += 1
        for a, c in occ_counter.items():
            if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT:
                cur_cost += 1
        if cur_cost &gt; cost_both:
            cost_both = cur_cost

    # set up the and/or graph
    graph = nx.Graph()
    for a, inputs in nodes.items():
        graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
        graph.add_edges_from([ (a, v) for v in inputs[1] ])
        
    td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
    cost_none = td.width

    # approximate final width when using or strategy
    # set up the and/or graph
    graph = nx.Graph()
    for a, inputs in nodes.items():
        if inputs[0] == AND or inputs[0] == GUESS:
            graph.add_edges_from(sum([ [ (v, vp) for v in inputs[1] if v != vp ] for vp in inputs[1] ], []))
        graph.add_edges_from([ (a, v) for v in inputs[1] ])
        if inputs[0] != AND and inputs[0] != GUESS:
            graph.add_edges_from([ (a + cur_max, v) for v in inputs[1] ])
        
    td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = str(float(config.config[&#34;decot&#34;])/3))
    cost_or = 0
    for t in td.bag_iter():
        for tp in t.children:
            tp.parent = t

    for t in td.bag_iter():
        cur_cost = len(t.vertices)
        if t != td.get_root():
            kept = t.vertices.intersection(t.parent.vertices)
        else:
            kept = set()
        occ_counter = { a : 0 for a in t.vertices }
        for a in kept: 
            occ_counter[a] += 1
        for tp in t.children:
            for a in tp.vertices.intersection(t.vertices):
                occ_counter[a] += 1
        for a, c in occ_counter.items():
            if c &gt;= 3 and a &gt; cur_max and nodes[a - cur_max][0] != INPUT and nodes[a - cur_max][0] != AND and nodes[a - cur_max][0] != GUESS:
                cur_cost += 1
        if cur_cost &gt; cost_or:
            cost_or = cur_cost

    logger.debug(f&#34;Approximate expected treewidth using strategy none: {cost_none}&#34;)
    logger.debug(f&#34;Approximate expected treewidth using strategy or: {cost_or}&#34;)
    logger.debug(f&#34;Approximate expected treewidth using strategy both/adaptive: {cost_both}&#34;)
    logger.info(&#34;------------------------------------------------------------&#34;)

    if cost_none &lt;= min(cost_both, cost_or) + 1:
        logger.info(f&#34;Choosing Unguided Clark Completion&#34;)
        logger.info(&#34;------------------------------------------------------------&#34;)
        self.clark_completion()
    elif cost_or &lt;= cost_both + 1:
        logger.info(f&#34;Choosing OR-guided Clark Completion&#34;)
        logger.info(&#34;------------------------------------------------------------&#34;)
        self.td_guided_clark_completion()
    else:
        logger.info(f&#34;Choosing completely guided Clark Completion&#34;)
        logger.info(&#34;------------------------------------------------------------&#34;)
        self.td_guided_both_clark_completion(adaptive=True, latest = True)</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.clark_completion"><code class="name flex">
<span>def <span class="ident">clark_completion</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies the clark completion to the program. </p>
<p>Does not check whether the program is tight!
Does not use tree decomposition guidance to obtain a program of possibly smaller treewidth.</p>
<p>Does not return anything only constructs the cnf.
The CNF can be obtained by using <code>get_cnf()</code>.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clark_completion(self):
    &#34;&#34;&#34;Applies the clark completion to the program. 

    Does not check whether the program is tight! 
    Does not use tree decomposition guidance to obtain a program of possibly smaller treewidth.
    
    Does not return anything only constructs the cnf.
    The CNF can be obtained by using `get_cnf()`.

    Returns:
        None        
    &#34;&#34;&#34;
    self._cnf = CNF()
    self._cnf.nr_vars = self._max
    # local method to get a new auxilliary variable
    # so that the atom counter of the program does not change
    def aux_var():
        self._cnf.nr_vars += 1
        self._cnf.auxilliary.add(self._cnf.nr_vars)
        return self._cnf.nr_vars

    perAtom = {}
    for a in self._deriv:
        perAtom[a] = []

    for r in self._program:
        for a in r.head:
            perAtom[a].append(r)

    for head in self._deriv:
        ors = []
        for r in perAtom[head]:
            ors.append(aux_var())
            ands = [-x for x in r.body]
            self._cnf.clauses.append([ors[-1]] + ands)
            for at in ands:
                self._cnf.clauses.append([-ors[-1], -at])
        self._cnf.clauses.append([-head] + [o for o in ors])
        for o in ors:
            self._cnf.clauses.append([head, -o])

    # handle the constraints
    constraints = [r for r in self._program if len(r.head) == 0]
    for r in constraints:
        self._cnf.clauses.append([-x for x in r.body])

    # handle the guesses
    for r in self._exactlyOneOf:
        # at least one
        self._cnf.clauses.append(list(r))
        # at most one
        for v in r:
            for vp in r:
                if v &lt; vp:
                    self._cnf.clauses.append([-v, -vp])
                        
    self._finalize_cnf()</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.encoding_stats"><code class="name flex">
<span>def <span class="ident">encoding_stats</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Print the stats of a tree decomposition of the cnf. </p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def encoding_stats(self):
    &#34;&#34;&#34;Print the stats of a tree decomposition of the cnf. 

    Returns:
        None        
    &#34;&#34;&#34;
    primal = Hypergraph()
    primal.add_nodes_from(range(1, self._max + 1))
    primal.add_edges_from([ set([ abs(x) for x in c ]) for c in self._cnf.clauses ])
    td = treedecomposition.from_hypergraph(primal)
    logger.info(f&#34;Tree Decomposition #bags: {td.bags} CNF treewidth: {td.width} #vertices: {td.vertices}&#34;)      </code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.get_cnf"><code class="name flex">
<span>def <span class="ident">get_cnf</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Used to get the extended cnf corresponding to the program. </p>
<p>Only possible after having called <code>tpUnfold()</code> and one of the Clark completion methods.</p>
<h2 id="returns">Returns</h2>
<p>:obj:<code><a title="aspmc.compile.cnf.CNF" href="../compile/cnf.html#aspmc.compile.cnf.CNF">CNF</a></code>: Returns the extended cnf of the program.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cnf(self):
    &#34;&#34;&#34;Used to get the extended cnf corresponding to the program. 

    Only possible after having called `tpUnfold()` and one of the Clark completion methods.
    
    Returns:
        :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
    &#34;&#34;&#34;
    return self._cnf</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.get_queries"><code class="name flex">
<span>def <span class="ident">get_queries</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the queries (names not literals). </p>
<p>Should be overwritten by subclasses.</p>
<h2 id="returns">Returns</h2>
<p>:obj:<code>list</code>: A list of queries.
The empty list corresponds to asking for the overall weight of the program.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_queries(self):
    &#34;&#34;&#34;Get the queries (names not literals). 

    Should be overwritten by subclasses.

    Returns:
        :obj:`list`: A list of queries. 
            The empty list corresponds to asking for the overall weight of the program.
    &#34;&#34;&#34;
    return []</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.get_weights"><code class="name flex">
<span>def <span class="ident">get_weights</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the weights of all the literals. </p>
<p>Should be overwritten by subclasses.</p>
<h2 id="returns">Returns</h2>
<p>:obj:<code>list</code>: A list of <code>weights</code> as numpy arrays.
<br>
The weight of literal <code>v</code> is in <code>weights[2*(v-1)]</code>, the one for <code>-v</code> is in <code>weights[2*(v-1)+1]</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_weights(self):
    &#34;&#34;&#34;Get the weights of all the literals. 

    Should be overwritten by subclasses.

    Returns:
        :obj:`list`: A list of `weights` as numpy arrays.      
            The weight of literal `v` is in `weights[2*(v-1)]`, the one for `-v` is in `weights[2*(v-1)+1]`
    &#34;&#34;&#34;
    return [ np.array([1.0]) for _ in range(self._max*2) ]</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.less_than_cycle_breaking"><code class="name flex">
<span>def <span class="ident">less_than_cycle_breaking</span></span>(<span>self, opt=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def less_than_cycle_breaking(self, opt = True):
    self._computeComponents()
    # here we remember the new rules
    new_rules = []
    # a dictionary that remembers the variables that we use for the lessThan predicate between atoms
    lessThan = {}

    # a subroutine to generate x &lt; x&#39;
    def getLessThan(x, xp):
        negated = x &gt; xp
        if negated:
            x,xp = xp,x
        # setup and check if this has already been handled
        if not (x,xp) in lessThan:
            lessThan[(x,xp)] = self._new_var(f&#34;less_than({x},{xp})&#34;)
            # add the atoms as guesses
            self._guess.add(lessThan[(x,xp)])
        else:
            return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

        # check if x and xp are in differens components
        xs_comp = self._condensation.graph[&#34;mapping&#34;][x]
        xps_comp = self._condensation.graph[&#34;mapping&#34;][xp]
        if xs_comp != xps_comp:
            # determine which is in the higher component
            if nx.algorithms.shortest_paths.generic.has_path(self._condensation, xs_comp, xps_comp):
                new_rules.append(Rule([], [-lessThan[(x,xp)]]))
            elif nx.algorithms.shortest_paths.generic.has_path(self._condensation, xps_comp, xs_comp):
                new_rules.append(Rule([], [lessThan[(x,xp)]]))
            else: # there is no connection between these at all. should not occur.
                logger.error(&#34;No connection between nodes that need to be connected!&#34;)
                exit(1)

        return -lessThan[(x,xp)] if negated else lessThan[(x,xp)]

    ts = nx.topological_sort(self._condensation)
    for t in ts:
        comp = self._condensation.nodes[t][&#34;members&#34;]
        if len(comp) &gt; 1:
            # antisymmetry and connexity are true automatically
            if opt:
                x_values = self._compute_backdoor(t)
            else:
                x_values = comp
            # transitivity
            for x in x_values:
                for y in comp:
                    if x == y:
                        continue
                    if opt:
                        z_values = self.dep.successors(y)
                    else:
                        z_values = comp
                    for z in z_values:
                        if y != z and x != z:
                            new_rules.append(Rule([], [getLessThan(x,y), getLessThan(y,z), -getLessThan(x,z)]))
                    
    
    # add lessThan atoms to break the cycles reduction
    for r in self._program:
        if len(r.head) &gt; 0:
            to_add = []
            head = r.head[0]
            for a in r.body:
                if a &gt; 0:
                    to_add.append(getLessThan(a, head))
            new_rules.append(Rule([], [-head] + r.body))
            r.body += to_add
        new_rules.append(r)
    self._program = new_rules</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.td_guided_both_clark_completion"><code class="name flex">
<span>def <span class="ident">td_guided_both_clark_completion</span></span>(<span>self, adaptive=False, latest=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies the clark completion to the program. </p>
<p>Does not check whether the program is tight!
Use tree decomposition guidance on both the "ands" and the "ors"
to obtain a program of possibly smaller treewidth.</p>
<p>Does not return anything only constructs the cnf.
The CNF can be obtained by using <code>get_cnf()</code>.</p>
<p>The solver to compute the tree decomposition and its timeout can be specified in
aspmc.config.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def td_guided_both_clark_completion(self, adaptive = False, latest = True): 
    &#34;&#34;&#34;Applies the clark completion to the program. 

    Does not check whether the program is tight! 
    Use tree decomposition guidance on both the &#34;ands&#34; and the &#34;ors&#34;
    to obtain a program of possibly smaller treewidth.
    
    Does not return anything only constructs the cnf.
    The CNF can be obtained by using `get_cnf()`.

    The solver to compute the tree decomposition and its timeout can be specified in 
    aspmc.config.

    Returns:
        None        
    &#34;&#34;&#34;
    self._cnf = CNF()
    self._cnf.nr_vars = self._max
    # local method to get a new auxilliary variable
    # so that the atom counter of the program does not change
    def aux_var():
        self._cnf.nr_vars += 1
        self._cnf.auxilliary.add(self._cnf.nr_vars)
        return self._cnf.nr_vars

    # remember whats an and, whats an or and whats a constraint
    # also include the guesses, which guess exactly one of their inputs to be true
    OR = 0
    AND = 1
    CON = 2
    GUESS = 3
    INPUT = 4
    nodes = { a : (OR, set()) for a in self._deriv }

    exactly_one_to_var = {}
    for a in self._exactlyOneOf:
        exactly_one_to_var[a] = aux_var()
        nodes[exactly_one_to_var[a]] = (GUESS, set(a))

    for atom in self._guess:
        nodes[atom] = (INPUT, set())

    if not latest:
        seen = set()
        facts = set([ r.head[0] for r in self._program if len(r.body) == 0 ])
        for f in facts:
            self._cnf.clauses.append([f])
        seen.update(facts)
    
    if not latest:
        remaining = [ r for r in self._program if len(r.head) == 0 or r.head[0] not in facts ]
    else:
        remaining = self._program
    for r in remaining:
        r.proven = aux_var()
        if len(r.head) != 0:
            nodes[r.proven] = (AND, set(r.body))
            nodes[abs(r.head[0])][1].add(r.proven)
            if not latest:
                seen.add(r.head[0])
        else:
            nodes[r.proven] = (CON, set([ -atom for atom in r.body ]))

    if not latest:
        # handle the atoms that do not occur in the head of any rule
        falses = [ a for a in self._deriv if a not in seen and nodes[a][0] == OR and len(nodes[a][1]) == 0 ]
        for f in falses:
            self._cnf.clauses.append([-f])

    # set up the and/or graph
    graph = nx.Graph()
    graph.add_nodes_from(range(1, self._cnf.nr_vars + 1))
    for r in self._program:
        if len(r.body) &gt; 0:
            for atom in r.head:
                graph.add_edge(atom, r.proven)
                if adaptive:
                    graph.add_edge(atom + self._cnf.nr_vars, r.proven)
            for atom in r.body:
                graph.add_edge(r.proven, abs(atom))
                if adaptive:
                    graph.add_edge(r.proven + self._cnf.nr_vars, abs(atom))
    
    for a in self._exactlyOneOf:
        for atom in a:
            graph.add_edge(exactly_one_to_var[a], atom)
            if adaptive:
                graph.add_edge(exactly_one_to_var[a] + self._cnf.nr_vars, atom)


    td = treedecomposition.from_graph(graph, solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
    if adaptive:
        td.remove(set(range(self._cnf.nr_vars + 1, 2*self._cnf.nr_vars + 1)))
        td.vertices = self._cnf.nr_vars 
    logger.info(f&#34;Tree Decomposition #bags: {td.bags} unfolded treewidth: {td.width} #vertices: {td.vertices}&#34;)

    
    if latest:
        # at which td node each variable occurs last
        last = {}
        idx = 0
        for t in td.bag_iter():
            for a in t.vertices:
                last[a] = idx
            t.idx = idx
            idx += 1
    
    # remember per bag which nodes have which partial result
    unfinished = {}
    # handle the bags in dfs order
    for t in td.bag_iter():
        unfinished[t] = {}
        # first take care of what we got from the children
        for tp in t.children:
            for atom in unfinished[tp]:
                if atom not in unfinished[t]:
                    unfinished[t][atom] = unfinished[tp][atom]
                else:
                    if len(unfinished[tp][atom]) == 1:
                        first_lit = unfinished[tp][atom].pop()
                    else:
                        node_type = nodes[atom][0]
                        first_lit = aux_var()
                        if node_type == AND:
                            bigAnd = [ first_lit ] + [ -v for v in unfinished[tp][atom] ]
                            self._cnf.clauses.append(bigAnd)                  
                            for v in unfinished[tp][atom]:
                                self._cnf.clauses.append([ -first_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[tp][atom]:
                                self._cnf.clauses.append([ first_lit, -v ])
                        elif node_type == GUESS:
                            # remember in first_lit, whether one of the unfinished atoms is true
                            bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[tp][atom]:
                                self._cnf.clauses.append([ first_lit, -v ])
                            # make sure that not more than one of the unfinished atoms is true
                            for v in unfinished[tp][atom]:
                                for vp in unfinished[tp][atom]:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])

                    if len(unfinished[t][atom]) == 1:
                        second_lit = unfinished[t][atom].pop()
                    else:
                        node_type = nodes[atom][0]
                        second_lit = aux_var()
                        if node_type == AND:
                            bigAnd = [ second_lit ] + [ -v for v in unfinished[t][atom] ]
                            self._cnf.clauses.append(bigAnd)
                            for v in unfinished[t][atom]:
                                self._cnf.clauses.append([ -second_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][atom]:
                                self._cnf.clauses.append([ second_lit, -v ])
                        elif node_type == GUESS:
                            # remember in second_lit, whether one of the unfinished atoms is true
                            bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][atom]:
                                self._cnf.clauses.append([ second_lit, -v ])
                            # make sure that not more than one of the unfinished atoms is true
                            for v in unfinished[t][atom]:
                                for vp in unfinished[t][atom]:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])

                    unfinished[t][atom] = set([first_lit, second_lit])
                    
        if not latest:
            # then take care of the current bag
            for a in t.vertices:
                node_type, inputs = nodes[a]
                todo_new = set([ atom for atom in inputs if abs(atom) in t.vertices ])
                if len(todo_new) == 0:
                    continue
                inputs.difference_update(todo_new)
                if a not in unfinished[t]:
                    unfinished[t][a] = todo_new
                else:
                    if len(unfinished[t][a]) == 1:
                        first_lit = unfinished[t][a].pop()
                    else:
                        first_lit = aux_var()
                        if node_type == AND:
                            bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigAnd)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ -first_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ first_lit, -v ])
                        elif node_type == GUESS:
                            # remember in first_lit, whether one of the unfinished atoms is true
                            bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ first_lit, -v ])
                            # make sure that not more than one of the unfinished atoms is true
                            for v in unfinished[t][a]:
                                for vp in unfinished[t][a]:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])

                    if len(todo_new) == 1:
                        second_lit = todo_new.pop()
                    else:
                        second_lit = aux_var()
                        if node_type == AND:
                            bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                            self._cnf.clauses.append(bigAnd)
                            for v in todo_new:
                                self._cnf.clauses.append([ -second_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -second_lit ] + [ v for v in todo_new ]
                            self._cnf.clauses.append(bigOr)
                            for v in todo_new:
                                self._cnf.clauses.append([ second_lit, -v ])
                        elif node_type == GUESS:
                            # remember in second_lit, whether one of the unfinished atoms is true
                            bigOr = [ -second_lit ] + [ v for v in todo_new ]
                            self._cnf.clauses.append(bigOr)
                            for v in todo_new:
                                self._cnf.clauses.append([ second_lit, -v ])
                            # make sure that not more than one of the unfinished atoms is true
                            for v in todo_new:
                                for vp in todo_new:
                                    if v &lt; vp:
                                        self._cnf.clauses.append([-v, -vp])

                    unfinished[t][a] = set([first_lit, second_lit])

            
            # check which nodes are completely done and finalize them
            new_unfinished = {}
            for a in unfinished[t]:
                if a in t.vertices: # if the variable is still there, we keep it
                    new_unfinished[a] = unfinished[t][a]
                else: # otherwise we finalize the node
                    node_type = nodes[a][0]
                    if node_type == AND:
                        bigAnd = [ a ] + [ -v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigAnd)
                        for v in unfinished[t][a]:
                            self._cnf.clauses.append([ -a, v ])
                    elif node_type == OR:
                        bigOr = [ -a ] + [ v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigOr)
                        for v in unfinished[t][a]:
                            self._cnf.clauses.append([ a, -v ])
                    elif node_type == CON:
                        bigOr = [ v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigOr)
                        self._cnf.clauses.append([-a])
                    elif node_type == GUESS:
                        # make sure that at least one of the unfinished atoms is true
                        bigOr = [ v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigOr)
                        # make sure that not more than one of the unfinished atoms is true
                        for v in unfinished[t][a]:
                            for vp in unfinished[t][a]:
                                if v &lt; vp:
                                    self._cnf.clauses.append([-v, -vp])
                        self._cnf.clauses.append([-a])

            unfinished[t] = new_unfinished
        else:
            # then take care of the current bag
            for a in t.vertices:
                node_type, inputs = nodes[a]
                if t.idx == last[a]:
                    if a in unfinished[t]:
                        if len(unfinished[t][a]) == 1:
                            inputs.add(unfinished[t][a].pop())
                        else:
                            new_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ new_lit ] + [ -v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ -new_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ new_lit, -v ])
                            elif node_type == GUESS:
                                # remember in new_lit, whether one of the unfinished atoms is true
                                bigOr = [ -new_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ new_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][a]:
                                    for vp in unfinished[t][a]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])
                            inputs.add(new_lit)
                        del unfinished[t][a]
                    if node_type == AND:
                        bigAnd = [ a ] + [ -v for v in inputs ]
                        self._cnf.clauses.append(bigAnd)
                        for v in inputs:
                            self._cnf.clauses.append([ -a, v ])
                    elif node_type == OR:
                        bigOr = [ -a ] + [ v for v in inputs ]
                        self._cnf.clauses.append(bigOr)
                        for v in inputs:
                            self._cnf.clauses.append([ a, -v ])
                    elif node_type == CON:
                        bigOr = [ v for v in inputs ]
                        self._cnf.clauses.append(bigOr)
                        self._cnf.clauses.append([-a])
                    elif node_type == GUESS:
                        # make sure that at least one of the unfinished atoms is true
                        bigOr = [ v for v in inputs ]
                        self._cnf.clauses.append(bigOr)
                        # make sure that not more than one of the unfinished atoms is true
                        for v in inputs:
                            for vp in inputs:
                                if v &lt; vp:
                                    self._cnf.clauses.append([-v, -vp])
                        self._cnf.clauses.append([-a])
                    inputs.clear()
                elif any([ t.idx == last[abs(b)] for b in inputs ]):
                    todo_new = set([ b for b in inputs if abs(b) in t.vertices ])
                    inputs.difference_update(todo_new)
                    if a not in unfinished[t]:
                        unfinished[t][a] = todo_new
                    else:
                        if len(unfinished[t][a]) == 1:
                            first_lit = unfinished[t][a].pop()
                        else:
                            first_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                            elif node_type == GUESS:
                                # remember in first_lit, whether one of the unfinished atoms is true
                                bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][a]:
                                    self._cnf.clauses.append([ first_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in unfinished[t][a]:
                                    for vp in unfinished[t][a]:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])

                        if len(todo_new) == 1:
                            second_lit = todo_new.pop()
                        else:
                            second_lit = aux_var()
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                                self._cnf.clauses.append(bigAnd)
                                for v in todo_new:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                            elif node_type == GUESS:
                                # remember in second_lit, whether one of the unfinished atoms is true
                                bigOr = [ -second_lit ] + [ v for v in todo_new ]
                                self._cnf.clauses.append(bigOr)
                                for v in todo_new:
                                    self._cnf.clauses.append([ second_lit, -v ])
                                # make sure that not more than one of the unfinished atoms is true
                                for v in todo_new:
                                    for vp in todo_new:
                                        if v &lt; vp:
                                            self._cnf.clauses.append([-v, -vp])
                        unfinished[t][a] = set([first_lit, second_lit])

    if not latest:
        # finalize the nodes that are left in the root
        root = td.get_root()
        for a in unfinished[root]:
            node_type = nodes[a][0]
            if node_type == AND:
                bigAnd = [ a ] + [ -v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigAnd)
                for v in unfinished[root][a]:
                    self._cnf.clauses.append([ -a, v ])
            elif node_type == OR:
                bigOr = [ -a ] + [ v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigOr)
                for v in unfinished[root][a]:
                    self._cnf.clauses.append([ a, -v ])
            elif node_type == CON:
                bigOr = [ v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigOr)
                self._cnf.clauses.append([-a])
            elif node_type == GUESS:
                # make sure that at least one of the unfinished atoms is true
                bigOr = [ v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigOr)
                # make sure that not more than one of the unfinished atoms is true
                for v in unfinished[root][a]:
                    for vp in unfinished[root][a]:
                        if v &lt; vp:
                            self._cnf.clauses.append([-v, -vp])
                self._cnf.clauses.append([-a])

    self._finalize_cnf()</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.td_guided_clark_completion"><code class="name flex">
<span>def <span class="ident">td_guided_clark_completion</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies the clark completion to the program. </p>
<p>Does not check whether the program is tight!
Use tree decomposition guidance on the "ors" to obtain a program of possibly smaller treewidth.</p>
<p>Does not return anything only constructs the cnf.
The CNF can be obtained by using <code>get_cnf()</code>.</p>
<p>The solver to compute the tree decomposition and its timeout can be specified in
aspmc.config.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def td_guided_clark_completion(self):        
    &#34;&#34;&#34;Applies the clark completion to the program. 

    Does not check whether the program is tight! 
    Use tree decomposition guidance on the &#34;ors&#34; to obtain a program of possibly smaller treewidth.
    
    Does not return anything only constructs the cnf.
    The CNF can be obtained by using `get_cnf()`.

    The solver to compute the tree decomposition and its timeout can be specified in 
    aspmc.config.

    Returns:
        None        
    &#34;&#34;&#34;
    self._cnf = CNF()
    self._cnf.nr_vars = self._max
    # local method to get a new auxilliary variable
    # so that the atom counter of the program does not change
    def aux_var():
        self._cnf.nr_vars += 1
        self._cnf.auxilliary.add(self._cnf.nr_vars)
        return self._cnf.nr_vars
    
    self._decomposeGraph(solver = config.config[&#34;decos&#34;], timeout = config.config[&#34;decot&#34;])
    logger.info(f&#34;Tree Decomposition #bags: {self._td.bags} unfolded treewidth: {self._td.width} #vertices: {self._td.vertices}&#34;)
    # at which td node to handle each rule
    rules = {}
    # at which td node each variable occurs last
    last = {}
    idx = 0
    td_idx = list(self._td)
    for t in self._td.bag_iter():
        for a in t.vertices:
            last[a] = idx
        t.idx = idx
        idx += 1
        rules[t] = []

    for r in self._program:
        for a in r.head:
            r.proven = aux_var()
            ands = [-x for x in r.body]
            self._cnf.clauses.append([ r.proven ] + ands)
            for at in ands:
                self._cnf.clauses.append([ -r.proven, -at ])
        idx = min([ last[abs(b)] for b in r.body + r.head ])
        rules[self._td.get_bag(td_idx[idx])].append(r)

    # how many rules have we used and what is the last used variable
    unfinished = {}
    for t in self._td.bag_iter():
        unfinished[t] = {}
        t.vertices = set(t.vertices)
        to_handle = {}
        for a in t.vertices:
            to_handle[a] = []
        for tp in t.children:
            removed = tp.vertices.difference(t.vertices)
            for a in removed:
                if a in self._deriv:
                    if a in unfinished[tp]:
                        final = unfinished[tp].pop(a)
                        self._cnf.clauses.append([-a, final])
                        self._cnf.clauses.append([a, -final])
                    else: 
                        self._cnf.clauses.append([-a])
            rest = tp.vertices.intersection(t.vertices)
            for a in rest:
                if a in unfinished[tp]:
                    to_handle[a].append(unfinished[tp][a])

        # take the rules we need
        for r in rules[t]:
            for a in r.head:
                to_handle[a].append(r.proven)

        # handle all the rules we have gathered
        for a in t.vertices:
            if len(to_handle[a]) &gt; 1:
                new_last = aux_var()
                self._cnf.clauses.append([-new_last] + to_handle[a])
                for at in to_handle[a]:
                    self._cnf.clauses.append([new_last, -at])
                unfinished[t][a] = new_last
            elif len(to_handle[a]) == 1:
                unfinished[t][a] = to_handle[a][0]

    for a in self._td.get_root().vertices:
        if a in self._deriv:
            if a in unfinished[self._td.get_root()]:
                final = unfinished[self._td.get_root()].pop(a)
                self._cnf.clauses.append([-a, final])
                self._cnf.clauses.append([a, -final])
            else: 
                self._cnf.clauses.append([-a])

    # handle the constraints
    constraints = [r for r in self._program if len(r.head) == 0]
    for r in constraints:
        self._cnf.clauses.append([-x for x in r.body])

   # handle the guesses
    for r in self._exactlyOneOf:
        # at least one
        self._cnf.clauses.append(list(r))
        # at most one
        for v in r:
            for vp in r:
                if v &lt; vp:
                    self._cnf.clauses.append([-v, -vp])

    self._finalize_cnf()</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.to_aig"><code class="name flex">
<span>def <span class="ident">to_aig</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_aig(self, path):
    varMap = { name : var for var, name in self._nameMap.items() }
    inputs = &#34;\n&#34;.join( str(2*(i+1)) for i,v in enumerate(self._guess) )
    nr_ands = 0
    cur_idx = len(self._guess)
    and_aig = &#34;&#34;
    graph = nx.DiGraph()
    for r in self._program:
        if len(r.body) &gt; 0:
            for atom in r.head:
                graph.add_edge(r, atom)
            for atom in r.body:
                graph.add_edge(abs(atom), r)
    ts = nx.topological_sort(graph)
    vertex_to_var = { v : 2*(i+1) for i,v in enumerate(self._guess) }
    for cur in ts:
        if isinstance(cur, Rule):
            if cur.body[0] &lt; 0:
                vertex_to_var[cur.body[0]] = vertex_to_var[-cur.body[0]] ^ 1
            new_bdd = vertex_to_var[cur.body[0]]
            for b in cur.body[1:]:
                if b &lt; 0:
                    vertex_to_var[b] = vertex_to_var[-b] ^ 1
                nr_ands += 1
                cur_idx += 1
                and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[b]}\n&#34;
                new_bdd = 2*cur_idx
            vertex_to_var[cur] = new_bdd
        elif cur not in self._guess:
            ins = list(graph.in_edges(nbunch=cur))
            new_bdd = vertex_to_var[ins[0][0]] ^ 1
            for r in ins[1:]:
                nr_ands += 1
                cur_idx += 1
                and_aig += f&#34;{2*cur_idx} {new_bdd} {vertex_to_var[r[0]] ^ 1}\n&#34;
                new_bdd = 2*cur_idx
            vertex_to_var[cur] = new_bdd ^ 1
    outputs = &#34;\n&#34;.join( str(vertex_to_var[varMap[name]]) for name in self.get_queries() )
    with open(path, &#34;w&#34;) as out_file:
        out_file.write(f&#34;aag {cur_idx} {len(self._guess)} 0 {len(self.get_queries())} {nr_ands}\n&#34;)
        out_file.write(f&#34;{inputs}\n&#34;)
        out_file.write(f&#34;{outputs}\n&#34;)
        out_file.write(f&#34;{and_aig}&#34;)</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.tpUnfold"><code class="name flex">
<span>def <span class="ident">tpUnfold</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies Tp-Unfolding to the program. </p>
<p>Applies a variant to be precise by first doing treeprocessing
and then Tp-Unfolding as this can be a bit better.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tpUnfold(self):
    &#34;&#34;&#34;Applies Tp-Unfolding to the program. 
    
    Applies a variant to be precise by first doing treeprocessing
    and then Tp-Unfolding as this can be a bit better.

    Returns:
        None        
    &#34;&#34;&#34;
    self._computeComponents()
    self.treeprocess()
    self._computeComponents()
    ts = nx.topological_sort(self._condensation)
    for t in ts:
        comp = self._condensation.nodes[t][&#34;members&#34;]
        if len(comp) &gt; 1:
            backdoor = self._compute_backdoor(t)
            # if the backdoor needs more than half the atoms it is better if we use all the atoms as the backdoor
            # this is because treeprocessing has another factor*2 and backdoor*2 &gt; comp
            backdoor = comp if len(backdoor) &gt; len(comp)/2 else backdoor
            self._backdoor_process(comp, backdoor)
    self._computeComponents()
    self.treeprocess()
    self._computeComponents()
    ts = nx.topological_sort(self._condensation)
    for t in ts:
        comp = self._condensation.nodes[t][&#34;members&#34;]
        if len(comp) &gt; 1:
            logger.error(&#34;Cycle breaking failed: the dependency graph still has a non-trivial SCC&#34;)
            exit(-1)</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.treeprocess"><code class="name flex">
<span>def <span class="ident">treeprocess</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies tree processing to the program. </p>
<p>This means that if there is a part of the dependency graph that is a tree and
only has one connection to the rest of the dependency graph, then it will be processed.</p>
<p>Results in one copy for each atom in the tree.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def treeprocess(self):
    &#34;&#34;&#34;Applies tree processing to the program. 
    
    This means that if there is a part of the dependency graph that is a tree and
    only has one connection to the rest of the dependency graph, then it will be processed.

    Results in one copy for each atom in the tree.

    Returns:
        None        
    &#34;&#34;&#34;
    ins = {}
    outs = {}
    for a in self._deriv:
        ins[a] = set()
        outs[a] = set()

    for a in self._guess:
        ins[a] = set()
        outs[a] = set()

    for r in self._program:
        for a in r.head:
            ins[a].add(r)
        for b in r.body:
            if b &gt; 0:
                outs[b].add(r)
    ts = nx.topological_sort(self._condensation)
    ancs = {}
    decs = {}
    for t in ts:
        comp = self._condensation.nodes[t][&#34;members&#34;]
        for v in comp:
            ancs[v] = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            decs[v] = set([vp[1] for vp in self.dep.out_edges(nbunch=v) if vp[1] in comp])
    q = set([v for v in ancs.keys() if len(ancs[v]) == 1 and len(decs[v]) == 1 and list(ancs[v])[0] == list(decs[v])[0]])
    while not len(q) == 0:
        old_v = q.pop()
        if len(ancs[old_v]) == 0:
            continue
        new_v = self._copy_var(old_v)
        self._deriv.add(new_v)
        ins[new_v] = set()
        outs[new_v] = set()
        anc = ancs[old_v].pop()
        ancs[anc].remove(old_v)
        decs[anc].remove(old_v)
        if len(ancs[anc]) == 1 and len(decs[anc]) == 1 and list(ancs[anc])[0] == list(decs[anc])[0]:
            q.add(anc)

        # this contains all rules that do not use anc to derive v
        to_rem = ins[old_v].difference(outs[anc])
        # this contains all rules that use anc to derive v
        # we just keep them as they are
        ins[old_v] = ins[old_v].intersection(outs[anc])
        # any rule that does not use anc to derive v can now only derive new_v
        for r in to_rem:
            head = [b if b != old_v else new_v for b in r.head]
            new_r = Rule(head,r.body)
            ins[new_v].add(new_r)
            for b in r.body:
                if b &gt; 0:
                    outs[b].remove(r)
                    outs[b].add(new_r)

        # this contains all rules that use v and derive anc
        to_rem = outs[old_v].intersection(ins[anc])
        # this contains all rules that use v and do not derive anc
        # we just keep them as they are
        outs[old_v] = outs[old_v].difference(ins[anc])
        # any rule that uses v to derive anc must use new_v
        for r in to_rem:
            body = [ (b if b != old_v else new_v) for b in r.body]
            new_r = Rule(r.head,body)
            for b in r.head:
                ins[b].remove(r)
                ins[b].add(new_r)
            for b in r.body:
                if b &gt; 0:
                    if b != old_v:
                        outs[abs(b)].remove(r)
                        outs[abs(b)].add(new_r)
                    else:
                        outs[new_v].add(new_r)
        new_r = Rule([old_v], [new_v])
        ins[old_v].add(new_r)
        outs[new_v].add(new_r)
    # only keep the constraints
    self._program = [r for r in self._program if len(r.head) == 0]
    # add all the other rules
    for a in ins.keys():
        self._program.extend(ins[a])</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.write_dimacs"><code class="name flex">
<span>def <span class="ident">write_dimacs</span></span>(<span>self, stream, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Write the extended cnf corresponding to the program to a stream. </p>
<p>Only possible after having called <code>tpUnfold()</code> and one of the Clark completion methods.</p>
<h2 id="args">Args</h2>
<p>stream (:obj:<code>stream</code>): The stream to write to. Must be binary.</p>
<h2 id="returns">Returns</h2>
<p>:obj:<code><a title="aspmc.compile.cnf.CNF" href="../compile/cnf.html#aspmc.compile.cnf.CNF">CNF</a></code>: Returns the extended cnf of the program.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_dimacs(self, stream, **kwargs):
    &#34;&#34;&#34;Write the extended cnf corresponding to the program to a stream. 

    Only possible after having called `tpUnfold()` and one of the Clark completion methods.
    
    Args:
        stream (:obj:`stream`): The stream to write to. Must be binary.

    Returns:
        :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
    &#34;&#34;&#34;
    # FIXME: this does not work anymore since auxilliary cnf vars do not have a name
    # if &#34;debug&#34; in kwargs:
    #     stream.write(f&#34;p cnf {self._cnf.nr_vars} {len(self._cnf.clauses)}\n&#34;.encode())
    #     for c in self._cnf.clauses:
    #         stream.write((&#34; &#34;.join([(&#34;(not &#34; if v &lt; 0 else &#34;(&#34;) + self._external_name(abs(v)) + &#34;)&#34; for v in c]) + &#34; 0\n&#34; ).encode())
    # else:
    self._cnf.to_stream(stream)</code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.Program.write_prog"><code class="name flex">
<span>def <span class="ident">write_prog</span></span>(<span>self, stream, spanning=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Write the (spanning) program to a stream.</p>
<h2 id="args">Args</h2>
<p>stream (:obj:<code>stream</code>): The stream to write to. Must be binary.
spanning (:obj:<code>bool</code>, optional): Whether the to write (case <code>False</code>) the actual program,
possibly with weights and utilities and such or (case <code>True</code>) only the spanning program.
The spanning program corresponds to the underlying logical theory.
Defaults to <code>False</code>.</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_prog(self, stream, spanning = False):
    &#34;&#34;&#34;Write the (spanning) program to a stream.

    Args:
        stream (:obj:`stream`): The stream to write to. Must be binary.
        spanning (:obj:`bool`, optional): Whether the to write (case `False`) the actual program,
            possibly with weights and utilities and such or (case `True`) only the spanning program. 
            The spanning program corresponds to the underlying logical theory.
            Defaults to `False`.

    Returns:
        None     
    &#34;&#34;&#34;
    if spanning:
        stream.write(Program._prog_string(self, self._program).encode())
    else:
        stream.write(self._prog_string(self._program).encode())</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="aspmc.programs.program.Rule"><code class="flex name class">
<span>class <span class="ident">Rule</span></span>
<span>(</span><span>head, body)</span>
</code></dt>
<dd>
<div class="desc"><p>A class for rules.</p>
<p>Implements a custom <code>__repr__</code> method.</p>
<p>Args:
<br>
head (:obj:<code>list</code>): The list of head atoms as dimacs literals. May be empty.
body (:obj:<code>list</code>): The list of body atoms as dimacs literals. May be empty.</p>
<h2 id="attributes">Attributes</h2>
<p>head (:obj:<code>list</code>): The list of head atoms as dimacs literals. May be empty.
body (:obj:<code>list</code>): The list of body atoms as dimacs literals. May be empty.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Rule(object):
    &#34;&#34;&#34;A class for rules.

    Implements a custom `__repr__` method.

    Args:        
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.

    Attributes:
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.
    &#34;&#34;&#34;
    def __init__(self, head, body):
        self.head = head
        self.body = body

    def __hash__(self):
        return hash((tuple(self.head), tuple(self.body)))

    def __eq__(self, other):
        if not isinstance(other, type(self)): 
            return NotImplemented
        return self.head == other.head and self.body == other.body

    def __repr__(self):
        return &#34;; &#34;.join([str(a) for a in self.head]) + &#34;:- &#34; + &#34;, &#34;.join([ (&#34;not &#34; if b &lt; 0 else &#34;&#34;) + str(abs(b)) for b in self.body]) </code></pre>
</details>
</dd>
<dt id="aspmc.programs.program.UnsupportedException"><code class="flex name class">
<span>class <span class="ident">UnsupportedException</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>raise this when the program relies on features that are not supported yet</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UnsupportedException(Exception):
    &#39;&#39;&#39;raise this when the program relies on features that are not supported yet&#39;&#39;&#39;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="aspmc.programs" href="index.html">aspmc.programs</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="aspmc.programs.program.Program" href="#aspmc.programs.program.Program">Program</a></code></h4>
<ul class="">
<li><code><a title="aspmc.programs.program.Program.binary_cycle_breaking" href="#aspmc.programs.program.Program.binary_cycle_breaking">binary_cycle_breaking</a></code></li>
<li><code><a title="aspmc.programs.program.Program.build_bdds" href="#aspmc.programs.program.Program.build_bdds">build_bdds</a></code></li>
<li><code><a title="aspmc.programs.program.Program.build_sdds" href="#aspmc.programs.program.Program.build_sdds">build_sdds</a></code></li>
<li><code><a title="aspmc.programs.program.Program.choose_clark_completion" href="#aspmc.programs.program.Program.choose_clark_completion">choose_clark_completion</a></code></li>
<li><code><a title="aspmc.programs.program.Program.clark_completion" href="#aspmc.programs.program.Program.clark_completion">clark_completion</a></code></li>
<li><code><a title="aspmc.programs.program.Program.encoding_stats" href="#aspmc.programs.program.Program.encoding_stats">encoding_stats</a></code></li>
<li><code><a title="aspmc.programs.program.Program.get_cnf" href="#aspmc.programs.program.Program.get_cnf">get_cnf</a></code></li>
<li><code><a title="aspmc.programs.program.Program.get_queries" href="#aspmc.programs.program.Program.get_queries">get_queries</a></code></li>
<li><code><a title="aspmc.programs.program.Program.get_weights" href="#aspmc.programs.program.Program.get_weights">get_weights</a></code></li>
<li><code><a title="aspmc.programs.program.Program.less_than_cycle_breaking" href="#aspmc.programs.program.Program.less_than_cycle_breaking">less_than_cycle_breaking</a></code></li>
<li><code><a title="aspmc.programs.program.Program.td_guided_both_clark_completion" href="#aspmc.programs.program.Program.td_guided_both_clark_completion">td_guided_both_clark_completion</a></code></li>
<li><code><a title="aspmc.programs.program.Program.td_guided_clark_completion" href="#aspmc.programs.program.Program.td_guided_clark_completion">td_guided_clark_completion</a></code></li>
<li><code><a title="aspmc.programs.program.Program.to_aig" href="#aspmc.programs.program.Program.to_aig">to_aig</a></code></li>
<li><code><a title="aspmc.programs.program.Program.tpUnfold" href="#aspmc.programs.program.Program.tpUnfold">tpUnfold</a></code></li>
<li><code><a title="aspmc.programs.program.Program.treeprocess" href="#aspmc.programs.program.Program.treeprocess">treeprocess</a></code></li>
<li><code><a title="aspmc.programs.program.Program.write_dimacs" href="#aspmc.programs.program.Program.write_dimacs">write_dimacs</a></code></li>
<li><code><a title="aspmc.programs.program.Program.write_prog" href="#aspmc.programs.program.Program.write_prog">write_prog</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="aspmc.programs.program.Rule" href="#aspmc.programs.program.Rule">Rule</a></code></h4>
</li>
<li>
<h4><code><a title="aspmc.programs.program.UnsupportedException" href="#aspmc.programs.program.UnsupportedException">UnsupportedException</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>